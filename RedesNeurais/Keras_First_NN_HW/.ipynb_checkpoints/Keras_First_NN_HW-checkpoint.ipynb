{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alunos: Aritana Noara Costa Santos  e Victor Augusto Januário da Cruz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Split arrays or matrices into random train and test subsets.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Standardize features by removing the mean and scaling to unit variance.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#confusion_matrix\n",
    "#precision_recall_curve:Compute precision-recall pairs for different probability thresholds.\n",
    "#roc_auc_score:\n",
    "#roc_curve:sensitivity and specificity\n",
    "#accuracy_score:summarize the ROC curve in a single value, aggregating all ROC thresholds\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "#prediction by committee is more accurate than that of any individual tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Python data visualization library based on matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (2.9.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/home/aritana/my_jupyter_notebook/my_jupyter_notebook/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (2.9.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: setuptools in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (57.0.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: packaging in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorflow) (20.9)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/aritana/my_jupyter_notebook/my_jupyter_notebook/lib/python3.8/site-packages (from packaging->tensorflow) (2.4.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.1.1 is available.\r\n",
      "You should consider upgrading via the '/home/aritana/my_jupyter_notebook/my_jupyter_notebook/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 17:13:31.027788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-29 17:13:31.027844: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "#sudo pip install keras\n",
    "\n",
    "\n",
    "from keras.models  import Sequential\n",
    "\n",
    "#Input:is used to instantiate a Keras tensor\n",
    "#Dense:implements the operation: output = activation(dot(input, kernel) + bias)\n",
    "#Flatten:Flattens the input. Does not affect the batch size.\n",
    "#Dropout:Dropout is a mechanism where in each training iteration (batch) we randomly remove a subset of neurons\n",
    "#BatchNormalization\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "#Optimizers\n",
    "from keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "\n",
    "##url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('pima-indians-diabetes.data', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>8</td>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.727</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>7</td>\n",
       "      <td>184</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.355</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>8</td>\n",
       "      <td>196</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "      <td>280</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.605</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "737               8                      65              72              23   \n",
       "29                5                     117              92               0   \n",
       "439               6                     107              88               0   \n",
       "209               7                     184              84              33   \n",
       "206               8                     196              76              29   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "737        0  32.0              0.600   42             0  \n",
       "29         0  34.1              0.337   38             0  \n",
       "439        0  36.8              0.727   31             0  \n",
       "209        0  35.5              0.355   41             1  \n",
       "206      280  37.5              0.605   57             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "#Because the data in the testing set already contains known values for the attribute\n",
    "#that you want to predict, it is easy to determine whether the model's guesses are correct\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.755\n",
      "roc-auc is 0.821\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy is 0.786 : Indica o número de previsões corretas no modelo. Neste caso 79% de acurácia, aproximadamente.\n",
    "\n",
    "### roc-auc is 0.832: Indica a media ou grau de separação, em como o modelo é capaz de distinguir entre as classes. É um valor próximo a 1, indica que o modelo está predizendo as classes de forma correta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 17:13:39.738335: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-29 17:13:39.738570: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aritana-Inspiron-5558): /proc/driver/nvidia/version does not exist\n",
      "2022-05-29 17:13:39.740360: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 121 parameters\n",
    "\n",
    "\n",
    "### 1 hidden layer, 12 hidden nodes, sigmoid activation:\n",
    "\n",
    "#### 12 bias terms input.\n",
    "\n",
    "### Final layer has just one node with a sigmoid activation (standard for binary classification):\n",
    "#### 1 bias term input.\n",
    "\n",
    "#### (12 * 8)conexões de entrada para camada oculta + 12 conexões coma camada de saida + 13 bias (12 com camada oculta e 1 com a camada de saída)  = 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 2s 21ms/step - loss: 0.6914 - accuracy: 0.5660 - val_loss: 0.6844 - val_accuracy: 0.5365\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.6836 - accuracy: 0.5851 - val_loss: 0.6779 - val_accuracy: 0.5365\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6764 - accuracy: 0.5955 - val_loss: 0.6717 - val_accuracy: 0.5521\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6695 - accuracy: 0.6042 - val_loss: 0.6659 - val_accuracy: 0.5833\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6631 - accuracy: 0.6042 - val_loss: 0.6605 - val_accuracy: 0.5833\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6571 - accuracy: 0.6181 - val_loss: 0.6554 - val_accuracy: 0.5938\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6514 - accuracy: 0.6389 - val_loss: 0.6506 - val_accuracy: 0.6094\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6461 - accuracy: 0.6406 - val_loss: 0.6461 - val_accuracy: 0.6042\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6411 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6094\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6363 - accuracy: 0.6615 - val_loss: 0.6377 - val_accuracy: 0.6302\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6318 - accuracy: 0.6632 - val_loss: 0.6339 - val_accuracy: 0.6302\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6276 - accuracy: 0.6649 - val_loss: 0.6302 - val_accuracy: 0.6302\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6235 - accuracy: 0.6771 - val_loss: 0.6267 - val_accuracy: 0.6406\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6197 - accuracy: 0.6875 - val_loss: 0.6234 - val_accuracy: 0.6354\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6160 - accuracy: 0.6875 - val_loss: 0.6203 - val_accuracy: 0.6406\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6125 - accuracy: 0.6927 - val_loss: 0.6173 - val_accuracy: 0.6458\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6092 - accuracy: 0.6997 - val_loss: 0.6144 - val_accuracy: 0.6562\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6060 - accuracy: 0.6979 - val_loss: 0.6116 - val_accuracy: 0.6719\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6030 - accuracy: 0.6997 - val_loss: 0.6090 - val_accuracy: 0.6719\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6000 - accuracy: 0.6979 - val_loss: 0.6065 - val_accuracy: 0.6771\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5972 - accuracy: 0.7014 - val_loss: 0.6040 - val_accuracy: 0.6823\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5945 - accuracy: 0.7014 - val_loss: 0.6017 - val_accuracy: 0.6875\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5918 - accuracy: 0.7066 - val_loss: 0.5994 - val_accuracy: 0.6875\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5892 - accuracy: 0.7101 - val_loss: 0.5972 - val_accuracy: 0.6823\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5868 - accuracy: 0.7101 - val_loss: 0.5951 - val_accuracy: 0.6927\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5844 - accuracy: 0.7118 - val_loss: 0.5931 - val_accuracy: 0.6875\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5820 - accuracy: 0.7118 - val_loss: 0.5912 - val_accuracy: 0.6927\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5798 - accuracy: 0.7101 - val_loss: 0.5893 - val_accuracy: 0.6927\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5776 - accuracy: 0.7101 - val_loss: 0.5874 - val_accuracy: 0.6927\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5754 - accuracy: 0.7083 - val_loss: 0.5856 - val_accuracy: 0.6979\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5734 - accuracy: 0.7135 - val_loss: 0.5839 - val_accuracy: 0.7083\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5714 - accuracy: 0.7153 - val_loss: 0.5822 - val_accuracy: 0.7083\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5694 - accuracy: 0.7153 - val_loss: 0.5805 - val_accuracy: 0.7083\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5674 - accuracy: 0.7135 - val_loss: 0.5789 - val_accuracy: 0.7083\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5656 - accuracy: 0.7118 - val_loss: 0.5774 - val_accuracy: 0.7135\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5638 - accuracy: 0.7101 - val_loss: 0.5758 - val_accuracy: 0.7135\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5620 - accuracy: 0.7118 - val_loss: 0.5744 - val_accuracy: 0.7135\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5602 - accuracy: 0.7101 - val_loss: 0.5729 - val_accuracy: 0.7135\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5586 - accuracy: 0.7101 - val_loss: 0.5715 - val_accuracy: 0.7240\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5569 - accuracy: 0.7118 - val_loss: 0.5701 - val_accuracy: 0.7240\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5553 - accuracy: 0.7118 - val_loss: 0.5687 - val_accuracy: 0.7240\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5536 - accuracy: 0.7135 - val_loss: 0.5674 - val_accuracy: 0.7240\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5521 - accuracy: 0.7153 - val_loss: 0.5661 - val_accuracy: 0.7240\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5505 - accuracy: 0.7153 - val_loss: 0.5649 - val_accuracy: 0.7240\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5490 - accuracy: 0.7222 - val_loss: 0.5637 - val_accuracy: 0.7292\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5475 - accuracy: 0.7222 - val_loss: 0.5625 - val_accuracy: 0.7292\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5461 - accuracy: 0.7205 - val_loss: 0.5613 - val_accuracy: 0.7292\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5447 - accuracy: 0.7205 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5432 - accuracy: 0.7188 - val_loss: 0.5590 - val_accuracy: 0.7292\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5419 - accuracy: 0.7205 - val_loss: 0.5579 - val_accuracy: 0.7292\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7222 - val_loss: 0.5569 - val_accuracy: 0.7292\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5392 - accuracy: 0.7240 - val_loss: 0.5558 - val_accuracy: 0.7292\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5379 - accuracy: 0.7240 - val_loss: 0.5547 - val_accuracy: 0.7292\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5366 - accuracy: 0.7257 - val_loss: 0.5537 - val_accuracy: 0.7292\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5353 - accuracy: 0.7292 - val_loss: 0.5527 - val_accuracy: 0.7292\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5341 - accuracy: 0.7292 - val_loss: 0.5517 - val_accuracy: 0.7344\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5329 - accuracy: 0.7309 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.7309 - val_loss: 0.5498 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5304 - accuracy: 0.7309 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5293 - accuracy: 0.7309 - val_loss: 0.5479 - val_accuracy: 0.7448\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5281 - accuracy: 0.7361 - val_loss: 0.5470 - val_accuracy: 0.7448\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5270 - accuracy: 0.7361 - val_loss: 0.5461 - val_accuracy: 0.7448\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5258 - accuracy: 0.7361 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5247 - accuracy: 0.7361 - val_loss: 0.5444 - val_accuracy: 0.7396\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5236 - accuracy: 0.7396 - val_loss: 0.5435 - val_accuracy: 0.7396\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5225 - accuracy: 0.7413 - val_loss: 0.5427 - val_accuracy: 0.7396\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5214 - accuracy: 0.7396 - val_loss: 0.5419 - val_accuracy: 0.7344\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5203 - accuracy: 0.7413 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5192 - accuracy: 0.7413 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5182 - accuracy: 0.7413 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5172 - accuracy: 0.7448 - val_loss: 0.5387 - val_accuracy: 0.7344\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5162 - accuracy: 0.7448 - val_loss: 0.5380 - val_accuracy: 0.7344\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5152 - accuracy: 0.7448 - val_loss: 0.5373 - val_accuracy: 0.7344\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5142 - accuracy: 0.7448 - val_loss: 0.5365 - val_accuracy: 0.7344\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5132 - accuracy: 0.7448 - val_loss: 0.5358 - val_accuracy: 0.7344\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5122 - accuracy: 0.7448 - val_loss: 0.5351 - val_accuracy: 0.7344\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5113 - accuracy: 0.7448 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5104 - accuracy: 0.7448 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5095 - accuracy: 0.7448 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5086 - accuracy: 0.7483 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5077 - accuracy: 0.7483 - val_loss: 0.5319 - val_accuracy: 0.7448\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.7500 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5060 - accuracy: 0.7535 - val_loss: 0.5306 - val_accuracy: 0.7448\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5052 - accuracy: 0.7535 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5044 - accuracy: 0.7517 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5036 - accuracy: 0.7535 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5028 - accuracy: 0.7552 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5020 - accuracy: 0.7552 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5012 - accuracy: 0.7552 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5005 - accuracy: 0.7569 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4997 - accuracy: 0.7569 - val_loss: 0.5262 - val_accuracy: 0.7500\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4990 - accuracy: 0.7569 - val_loss: 0.5256 - val_accuracy: 0.7500\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4983 - accuracy: 0.7569 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4976 - accuracy: 0.7569 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4969 - accuracy: 0.7569 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4962 - accuracy: 0.7569 - val_loss: 0.5236 - val_accuracy: 0.7500\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4955 - accuracy: 0.7569 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4949 - accuracy: 0.7569 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4942 - accuracy: 0.7569 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4936 - accuracy: 0.7587 - val_loss: 0.5218 - val_accuracy: 0.7552\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4929 - accuracy: 0.7587 - val_loss: 0.5214 - val_accuracy: 0.7552\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4923 - accuracy: 0.7622 - val_loss: 0.5210 - val_accuracy: 0.7552\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4917 - accuracy: 0.7622 - val_loss: 0.5205 - val_accuracy: 0.7552\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4911 - accuracy: 0.7622 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4904 - accuracy: 0.7674 - val_loss: 0.5198 - val_accuracy: 0.7552\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4898 - accuracy: 0.7674 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4892 - accuracy: 0.7674 - val_loss: 0.5190 - val_accuracy: 0.7552\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4887 - accuracy: 0.7674 - val_loss: 0.5186 - val_accuracy: 0.7552\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.7674 - val_loss: 0.5182 - val_accuracy: 0.7552\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4875 - accuracy: 0.7674 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4869 - accuracy: 0.7674 - val_loss: 0.5175 - val_accuracy: 0.7552\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4864 - accuracy: 0.7674 - val_loss: 0.5172 - val_accuracy: 0.7552\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4858 - accuracy: 0.7639 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4853 - accuracy: 0.7656 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4847 - accuracy: 0.7656 - val_loss: 0.5161 - val_accuracy: 0.7552\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7639 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4837 - accuracy: 0.7656 - val_loss: 0.5154 - val_accuracy: 0.7552\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4832 - accuracy: 0.7639 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4827 - accuracy: 0.7656 - val_loss: 0.5148 - val_accuracy: 0.7552\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4822 - accuracy: 0.7656 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4817 - accuracy: 0.7674 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4812 - accuracy: 0.7674 - val_loss: 0.5138 - val_accuracy: 0.7604\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4807 - accuracy: 0.7639 - val_loss: 0.5135 - val_accuracy: 0.7604\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4802 - accuracy: 0.7639 - val_loss: 0.5132 - val_accuracy: 0.7604\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4797 - accuracy: 0.7639 - val_loss: 0.5129 - val_accuracy: 0.7604\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4793 - accuracy: 0.7639 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4788 - accuracy: 0.7639 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4784 - accuracy: 0.7656 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4779 - accuracy: 0.7656 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4775 - accuracy: 0.7656 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4766 - accuracy: 0.7674 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.7691 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4757 - accuracy: 0.7691 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4749 - accuracy: 0.7708 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4745 - accuracy: 0.7708 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4741 - accuracy: 0.7726 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.7726 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4732 - accuracy: 0.7726 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4729 - accuracy: 0.7726 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.7726 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4721 - accuracy: 0.7726 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4717 - accuracy: 0.7726 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.7726 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.7726 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7743 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.5072 - val_accuracy: 0.7604\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.7743 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4695 - accuracy: 0.7743 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4692 - accuracy: 0.7726 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4688 - accuracy: 0.7726 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4685 - accuracy: 0.7726 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4666 - accuracy: 0.7726 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4663 - accuracy: 0.7726 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4654 - accuracy: 0.7726 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4651 - accuracy: 0.7726 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4648 - accuracy: 0.7726 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4645 - accuracy: 0.7708 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4642 - accuracy: 0.7691 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4639 - accuracy: 0.7691 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4637 - accuracy: 0.7691 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4634 - accuracy: 0.7691 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4631 - accuracy: 0.7691 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4629 - accuracy: 0.7726 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4626 - accuracy: 0.7726 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4616 - accuracy: 0.7726 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4611 - accuracy: 0.7743 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4609 - accuracy: 0.7743 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4606 - accuracy: 0.7743 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4604 - accuracy: 0.7743 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4600 - accuracy: 0.7743 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4593 - accuracy: 0.7743 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4591 - accuracy: 0.7743 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4589 - accuracy: 0.7743 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.4587 - accuracy: 0.7743 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4583 - accuracy: 0.7743 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4581 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4578 - accuracy: 0.7743 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4576 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4574 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4572 - accuracy: 0.7726 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4570 - accuracy: 0.7726 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.7726 - val_loss: 0.5012 - val_accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "#y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "\n",
    "\n",
    "predict_x = model_1.predict(X_test) \n",
    "y_pred_class_nn_1 = np.argmax(predict_x,axis=1)\n",
    "\n",
    "#O método \"predict_classes\" não funciona nas versões do Keras superior a 2.5 \n",
    "\n",
    "# A indicação da correção se encontra em https://keras.rstudio.com/reference/predict_proba.html#details. \n",
    "\n",
    "# usar: \n",
    "#y_pred_class_nn_1 = model_1.predict(X_test_norm)\n",
    "#y_pred_class_nn_1 = (y_pred_prob_nn_1 > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53559816],\n",
       "       [0.56501013],\n",
       "       [0.33758485],\n",
       "       [0.2791096 ],\n",
       "       [0.20052065],\n",
       "       [0.59508187],\n",
       "       [0.04426837],\n",
       "       [0.35369265],\n",
       "       [0.7867891 ],\n",
       "       [0.17987987]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.641\n",
      "roc-auc is 0.819\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8sklEQVR4nO3dd5iU1fn/8c9NV4SlitLVRRExWQiI8Yu6UWMJRqNGf4AKJhpTNCooTQFBRVQUxEQS10bQrL0Ee4muKIqAuNJBmhQBaUuHbef3xwxkWLfM7s7MmfJ+XReXOzPPznzm7Dj33Oc58zzmnBMAAIgfNXwHAAAAh6I4AwAQZyjOAADEGYozAABxhuIMAECcoTgDABBnKM5IOWZ2mJm9YWbbzewl33lSlZlNNrN7gj+fbmZLwvy9a8zss+im86ui52hmOWZ2XSwzIbYozknOzFaZ2V4z22VmG4JviEeU2OY0M/vIzHYGC9YbZtapxDYNzexhM1sdvK/lwcvNynhcM7ObzGy+me02s7Vm9pKZnRzN5xum30pqIampc+7y6t6ZmWWamTOzSSWu/8zMrgn+fE1wm8EltllrZpnVzRBGxtDXwcbQ10HoG33Ic3mtxO//NHh9TonrzcxWmNnC6uRzzn3qnDuhOvcRjlQo7EgOFOfU8Gvn3BGSMiR1kTTswA1m9nNJ70v6j6SWko6R9I2k6WZ2bHCbOpL+K+kkSedLaijp55K2SDqljMecKOlmSTdJaiLpeEmvS+pV2fBmVquyv1OBdpKWOucKI5hlt6Srzax9Ob++VdJgM2tQ2ceNkAOvg66SukkaXsZ2myT93MyahlzXX9LSUrY9Q9KRko41s+6RDJvMovCaRpKhOKcQ59wGSe8pUKQPeEDSFOfcROfcTufcVufccEkzJI0KbtNPUltJlzjnFjrnip1zPzjn7nbOvV3yccysg6QbJPVxzn3knNvvnNvjnPu3c+6+4DaHTMuV7GiCXdoNZvatpG/N7B9m9mCJx/mPmQ0M/tzSzF4xs01mttLMbiptDMxstKSRkv5fsIu81sxqmNlwM/vOzH4wsylmlhbcvn0wy7VmtlrSR2UMb56kyZLuLON2SVok6QtJA8vZJjRrWjDLpmC24WZWI3jbNcHO/EEz2xZ8zheEc7/OuXWS3pHUuYxN8hX4INU7+Fg1Jf0/Sf8uZdv+Cnywezv4c3nPp4uZzQnO0LwgqV7IbZlmtjbk8tDg7MxOM1toZpf8+O7s78GZnsVmdnbIDWlm9qSZrTezdWZ2j5nVNLMTJf1TgQ8eu8wsL7h93eA4rg7OKvzTzA4L3tbMzN40szwz22pmnx74G5Ty/JwFZotWmNlmMxtX4u813cwmmNkWSaPK+/tW9BxLeezfm9mi4GvhPTNrVyLXX8zs2+B43m1mx5nZ52a2w8xetMAHcMQRinMKMbPWki6QtCx4+XBJp0kqbb/ri5J+Gfz5HEnvOud2hflQZ0ta65ybWb3E+o2kHpI6SXpOgYJqkmRmjSWdK+n54BvaGwp0/K2Cj3+LmZ1X8g6dc3dKulfSC865I5xzT0q6JvjvF5KOlXSEpL+X+NUzJZ0o6Uf3GWKMpMvMrLzp2RHBbE3K2eaAv0lKC2Y6U4EPSb8Lub2HpCWSminwIevJA+NTHjNrI+lXkr4uZ7MpwceTAs95vqTvS9zP4QrsIvh38F/vst7kg9e/LukZBWZSXpJ0WTmPv1zS6Qo8/9GSnjWzo0Nu7xHcppkCH4heDRnTyZIKJaUrMFN0rqTrnHOLJP1J0hfBv32j4Pb3KTCzkxH8nVYKfICTpFslrZXUXIFdIbdLKu+Yx5coMCvRVdLFkn5fIvOK4P2MUXh/37Ke40FmdnEw16XBnJ8q8P9LqPMk/UzSqZIGS8qSdJWkNgp8SOtTznOCBxTn1PC6me2UtEbSD/pfd9dEgdfA+lJ+Z70CbwqS1LSMbcpS2e3LMjbYye9V4A3HKfCGLQWKwhfOue8ldZfU3Dl3l3Mu3zm3QtLjCnZ+YbhS0njn3IrgB5BhChSa0KnHUc653cEspQrOTPxT0l3lbJMr6QNJQ8oLFOxWe0saFpzRWCXpIUlXh2z2nXPucedckaR/STpagTf+srwe7BY/k/SJAh9Sysr5uaQmwQ8a/RQo1iVdKmm/ArtF3pJUW2Xvtjg1ePvDzrkC59zLkmaV8/gvOee+D87SvCDpWx26C+WHkPt6QYEPKb3MrIUCHzxuCf69fpA0QWW8FoIfZq6XNCD4WtupwLgc2L5AgXFtF3ysT135JyS4P3g/qyU9rEOL3vfOub8Fd6fkq+K/b6nPsZTH/JMC/68sCt73vZIyQrtnSQ8453Y45xYo8EHr/eDrfbsCsyhdynlO8IDinBp+45xrIClTUkf9r+huk1SswJtPSUdL2hz8eUsZ25SlstuXZc2BH4JviM/rf292ffW/adZ2kloGpx7zggXodpVfqEK1lPRdyOXvJNUq8ftrFJ77JZ1nZj8tZ5uRkv4cLCRlaaZAMSuZq1XI5Q0HfnDO7Qn+eMhivxJ+45xr5Jxr55z7S3kfNIKekXSjAjMKr5Vye39JLzrnCp1z+yS9orKntltKWleisH1XxrYys35mlhvy9+ys/71uVcZ9tVTgtVBb0vqQ331Mgf3ipWku6XBJX4Vs/27wekkap8BM0/vB6eqhZWUOCn2dHMhU2m3h/H3Leo4ltZM0MST/VklW4r42hvy8t5TL5b1u4AHFOYU45z5RYMrvweDl3QrsAy1txfIVCiwCk6QPFSg49cN8qP9Kam1m3crZZrcCb4oHHFVa5BKXn5P022BH0EOBYiAF3vRWBgvPgX8NnHO/CjPv9wq8wR3QVoFp0dA3sLBO3+ac26JAx3R3OdsslvSqpDvKuavNCnRtJXOtCydHhDwj6S+S3g4p/pIO7iI5S9JVFvgWwAYFZjN+ZaWv4F8vqVWJafe2pT1o8O/7uAIfDJoGp5/nK1BwDijtvr5X4LWwX1KzkNdCQ+fcScHtSv4dNytQnE4K2T4tuHBOwa72VufcsZIukjSwvH2/CkwTl8x0QOhjh/P3Les5lrRG0h9LvP4PC85+IEFRnFPPw5J+GdLZDZXUP7iQpYGZNbbAd09/rsC+PinwJr1G0itm1tECC6iamtntZvajAuic+1bSJEnPWWChTx0zq2dmvUM6j1xJl5rZ4WaWLunaioI7575W4E3tCUnvOefygjfNlLTTzIZY4DvMNc2ss4W/evg5SQPM7BgLfL3owD7pSq/mDhqvwL78E8vZZrQC+xcblXZjcKr6RUljgn+XdgosJHu2ipkqzTm3UoF9oaV9iLhagdXbJyiwrzZDgf22a1X6/ssvFPjAc5OZ1TazS1X2Sv/6ChSyTZJkZr/TjxevHRlyX5crMNZvO+fWKzDN/pAFvv5XI7j46czg721U4INjneBzLFbgg8AEMzsy+HitDqxXMLMLzSw9WCS3SypSYLapLIOC/w+1UeDbCi+UtlGYf99Sn2Mpd/dPScPM7KRg5rTg9khgFOcU45zbpMD+w5HBy58psFjkUgW6m+8U2P/UM1hk5Zzbr8CisMUK7C/doUBBbCbpyzIe6iYFFlU9qsBK5uUKLJZ5I3j7BAX2u21UYH9paSuBS5MdzJId8pyKJF2oQIFYqf8V8LQw7/MpBT6ATAv+/j5Jfw3zd3/EObdDgQVaZS76Cha+ZxQoRGX5qwIzDCsU2E+cHcwaM865z4L79UvqL2mSc25D6D8FCsWPpradc/kKvMauUWDa9f8pMHtQ2mMuVGD/6xcKvD5OljS9xGZfSuqgwN96jKTfBmctpMA+8jqSFiqw6+Zl/W83y0eSFkjaYGYHdtsMUWDqeoaZ7VBgpujAor4Owcu7gnkmOec+Li130H8kfaXAh8+3JD1ZzrYV/X3Le44HOedeU2B3yvPB/PMVWPiJBGblr20AAITDzJykDs65Zb6zIPHROQMAEGcozgAAxBmmtQEAiDN0zgAAxBmKMwAAcabCM6OY2VMKfE3lB+fcjw6UH/z+30QFDpm3R9I1zrk5Fd1vs2bNXPv27Q9e3r17t+rXD/cYF6gsxje6GN/oYWyji/GNnpJj+9VXX212zjUv51cOCue0ZZMV+L5qacfWlQLfp+sQ/NdD0j+C/y1X+/btNXv27IOXc3JylJmZGUYcVAXjG12Mb/QwttHF+EZPybE1szIPWVtShdPazrlpChw0oCwXK3DKQeecmyGpUYmzxwAAgEqIxAm/W+nQA7qvDV4XibMSAQBSSFZWlrKzsyveMAE0a9asyrMSkSjOYTOz6xU4PZtatGihnJycg7ft2rXrkMuILMY3uhjf6GFsoyvexnfSpElatmyZ0tPTfUepMuecNm7cqIyMjCqPbSSK8zodeiaW1irjzDnOuSwFTvKtbt26udBPFOz3iC7GN7oY3+hhbKMr3sa3UaNG6tatW1x9YKiM4uJiLVq0SHXq1NG6deuqPLaR+CrVVEn9LOBUSduDZ4YBACBlOOc0bNgwOefUoUOHat1XOF+lek5SpqRmZrZW0p0KnCRczrl/KnAKs18pcFaXPQqcBg8AgJRRUFCg6dOna+jQoWrcuHG176/C4uycK+3crKG3O0k3VDsJAAAJ6u6771a/fv0iUpilGC8IAwCgvBXZubm5ysjIiG2gati/f79eeeUV3XnnnapZs2bE7pfDdwIAYio7O1u5ubml3paRkaG+ffvGNlA1TJo0ST179oxoYZbonAEAHlTna0bxYPfu3Xrsscc0cODAqNw/nTMAAJX0+uuvR7XDpzgDABCm7du3a8iQIerbt6+OOuqoqD0OxRkAgDDk5+dr5syZGjJkiAInZIweijMAABXYvHmzBgwYoDPPPFNNmjSJ+uOxIAwAUkzoV5ny8vLUqFGjmD5+on1dasuWLfruu+80duxY1alTJyaPSecMACmmvK8yxUIifV1q/fr1GjlypDp27KiGDRvG7HHpnAEgBR34KlO8nfginqxdu1bbtm3TuHHjdPjhh8f0semcAQAoYf369XrggQfUoUOHmBdmic4ZAIBDLF++XDt37tS4ceNUt25dLxnonAEACNqxY4f+8Y9/6KSTTvJWmCU6ZwCIivJO7uBboq2WjpWFCxdq48aNGjduXNS/x1wROmcAiALfK6LLk0irpWOlsLBQr7zyis444wzvhVmicwaAqEn0kzukijlz5mjFihUaMWKE7ygH0TkDAFKWc06zZs3SZZdd5jvKIeicAQApafr06Zo/f77++Mc/+o7yI3TOAICUs3v3bm3btk3XX3+97yilonMGEFdKrnL2ceznSGBFdPz68MMPtWDBAt18882+o5SJzhlAXInnVc6VwYro+LRy5Uo1bdo0rguzROcMIA6FrnLm2M+IlDfffFOrV6/WX/7yF99RKkRxBgAkvc8++0zdu3fXhRde6DtKWJjWBgAktbffflvLli1TixYtfEcJG50zACBpvfrqqzr33HN1xBFH+I5SKRRnABERqWNJs8oZkTJt2jTl5+cnXGGWmNYGECGRWmXNKmdEwpNPPqnOnTurd+/evqNUCZ0zgIjhWNKIB/Pnz1ezZs3UpEkT31GqjM4ZAJA0Jk6cqMMPP1wXX3yx7yjVQnEGACSFNWvWqFOnTjr22GN9R6k2ijMAIKE553Tfffdp8+bN+uUvf+k7TkSwzxlAucJdhc0qa/jgnNPatWv1i1/8Ql26dPEdJ2LonAGUK9xV2KyyRqw55zR69Ght2LBBPXr08B0nouicAVSIVdiIN8XFxVqwYIGuuuoqpaen+44TcXTOAICE4pzT8OHDVVxcnJSFWaJzBgAkkMLCQuXk5GjIkCFKS0vzHSdq6JwBAAnj3nvvVZs2bZK6MEt0zkBMROq40z6wChvxID8/Xy+88IKGDx+uGjWSv69M/mcIxIFIHXfaB1ZhIx48/vjjOv3001OiMEt0zkDMsOIZqLy9e/fq73//uwYNGuQ7SkylxkcQAEDCcc7pjTfe0JVXXuk7SsxRnAEAcWfnzp0aNGiQfvvb36ply5a+48QcxRkAEFf27dunr776SkOHDk2ZfcwlpeazBgDEpa1bt2rgwIE69dRT1axZM99xvGFBGFANB74ilZeXp0aNGpW5HV9HAiq2ZcsWrV69WmPHjlW9evV8x/GKzhmoBk4KAUTGxo0bNXLkSKWnpyf9AUbCQecMVFNGRoZGjRqlzMxM31GAhPT9999r8+bNeuCBB1S/fn3fceICnTMAwJtNmzbpvvvuU4cOHSjMIeicAQBerFq1Slu2bNG4ceNUt25d33HiCp0zACDm9uzZo7/97W86+eSTKcyloHMGKqHkCSxYhQ1U3pIlS7Rq1So9+OCDMjPfceISnTNQCSVXZ7MKG6icoqIivfzyyzr77LMpzOWgcwYqqbQTWHBCC6Bi33zzjebPn6877rjDd5S4R+cMAIi64uJizZo1S3369PEdJSHQOQMAomrGjBmaNWuW/vrXv/qOkjDonAEAUbNz505t27ZNN954o+8oCYXiDFQgKytLmZmZyszMDOtQnQACcnJy9Nhjj+mCCy5g8VclUZyBCoSu0GZ1NhCeZcuWqUmTJrrtttt8R0lI7HMGwlDaCm0ApXv33Xe1dOlS3XTTTb6jJCyKMwAgYqZNm6auXbvq/PPP9x0loTGtDQCIiPfff19LlizRkUce6TtKwqNzBgBU26uvvqpzzjlH5557ru8oSYHOGQBQLV9++aX27t2rhg0b+o6SNCjOAIAqe/rpp9W+fXtdeeWVvqMkFYozAKBKvv32WzVs2FAtWrTwHSXpUJwBAJX26KOPqqioSJdddpnvKEmJ4gwAqJQNGzYoPT1dHTt29B0laVGcAQBhcc7pwQcf1OrVq3Xeeef5jpPUKM4AgAo557Ru3Tr17NlTp5xyiu84SY/iDAAol3NO99xzj9asWaNTTz3Vd5yUwEFIAABlcs5p3rx56tu3r4477jjfcVIGnTMAoEyjRo1SYWEhhTnG6JwBAD9SVFSkDz/8ULfddpsaNGjgO07KoXMGAPzIAw88oDZt2lCYPaFzBgAcVFBQoGeffVZDhgxRjRr0b75QnJESsrKylJ2dXaXfzc3NVUZGRmQDAXFq8uTJOuussyjMnjH6SAnZ2dnKzc2t0u9mZGSob9++kQ0ExJl9+/ZpzJgxuu6661j8FQfC6pzN7HxJEyXVlPSEc+6+Ere3lfQvSY2C2wx1zr0d2ahA9WRkZCgnJ8d3DCDuOOf0zjvvqH///jIz33GgMDpnM6sp6VFJF0jqJKmPmXUqsdlwSS8657pI6i1pUqSDAgAib+/evRo4cKB+/etfq3Xr1r7jICicae1TJC1zzq1wzuVLel7SxSW2cZIOnGU7TdL3kYsIAIiGvXv3atmyZRo2bJhq1WIJUjwJ56/RStKakMtrJfUosc0oSe+b2V8l1Zd0Tml3ZGbXS7peklq0aHHIFOOuXbuYcoyiVB/fvLw8SYraGKT6+EYTYxsdu3bt0uOPP66rrrpKCxcu1MKFC31HSjrVee1G6qNSH0mTnXMPmdnPJT1jZp2dc8WhGznnsiRlSVK3bt1cZmbmwdtycnIUehmRlSzjW9VV16tWrVJGRkbUxiBZxjceMbaRt3XrVq1Zs0aTJ0/WN998w/hGSXVeu+FMa6+T1CbkcuvgdaGulfSiJDnnvpBUT1KzKiUCylHVVdesuAYCNm/erBEjRqh9+/Zq3Lix7zgoQzid8yxJHczsGAWKcm9JJd/lVks6W9JkMztRgeK8KZJBgQNYdQ1UzYYNG7Rx40bdd999HPkrzlXYOTvnCiXdKOk9SYsUWJW9wMzuMrOLgpvdKukPZvaNpOckXeOcc9EKDQConG3btunuu+9Weno6hTkBhLXPOfid5bdLXDcy5OeFkv4vstEAAJGwevVqff/99xo/frzq1q3rOw7CwBHCACCJ7d+/XxMnTlSXLl0ozAmEL7YhLoS7CpvjXAPh+/bbb7VkyRI9+OCDHPkrwdA5Iy6EuwqbVddAeJxzevnll3X++edTmBMQnTPiBquwgciYP3++Zs+erWHDhvmOgiqicwaAJFJcXKzZs2erX79+vqOgGuicASBJzJ49W9OmTdPAgQN9R0E10TkDQBLYvn27tm7dqgEDBviOggigc4YXJVdnswobqLpPP/1U06dP19ChQ31HQYTQOcOLkquzWYUNVM2SJUvUpEkTDRkyxHcURBCdM7xhdTZQPR9++KHmzp3LPuYkRHEGgAQ0bdo0/eQnP9E555zjOwqigGltAEgwOTk5WrhwoY488kjfURAldM4AkEBee+01ZWZmKjMz03cURBGdMwAkiNzcXO3YsUONGzf2HQVRRnEGgATwzDPPqGnTpurfv7/vKIgBijMAxLnVq1erbt26atOmje8oiBGKMwDEsccee0zbtm3TFVdc4TsKYojiDABxatOmTWrbtq1++tOf+o6CGKM4A0AcmjBhgpYsWaILLrjAdxR4wFepACCOOOe0bt06nXbaaerRo4fvOPCEzhkA4oRzTmPHjtXKlSspzCmOzhkA4oBzTrm5uerTp4+OOeYY33HgGZ0zAMSBe+65R4WFhRRmSKJzBgCviouL9fbbb2vgwIGqX7++7ziIE3TOAODR+PHj1a5dOwozDkHnDAAeFBYW6umnn9att94qM/MdB3GG4owKZWVlKTs7O6L3mZubq4yMjIjeJ5BInn32WZ155pkUZpSKaW1UKDs7W7m5uRG9z4yMDPXt2zei9wkkgv379+uuu+5S//79dfzxx/uOgzhF54ywZGRkKCcnx3cMIKE55/Thhx+qf//+dMwoF50zAMTAnj17NGDAAP3yl79Uu3btfMdBnKM4A0CU7d27V/PmzdPQoUNVp04d33GQACjOABBFO3bs0G233aaOHTvqqKOO8h0HCYJ9zgAQJdu2bdPq1at11113KS0tzXccJBA6ZwCIgq1bt2r48OFq166dmjZt6jsOEgydMwBE2KZNm7Ru3TqNHTtWDRs29B0HCYjOGQAiaOfOnRo9erTS09MpzKgyOmcAiJB169Zp5cqVGj9+PKuyUS10zgAQAYWFhZo4caK6detGYUa10TknkfKOgZ2Xl6dGjRpV6X45DjZQvhUrVuibb77RAw884DsKkgSdcxKJxjGwJY6DDZTHOadXXnlFF154oe8oSCJ0zkmmrGNg5+TkKDMzM+Z5gGS2aNEiffrppxo0aJDvKEgydM4AUAVFRUX66quvdO211/qOgiRE5wwAlfT111/r/fff15AhQ3xHQZKicwaASti2bZu2bdvGVDaiiuIMAGH6/PPP9eijj+qss85SjRq8fSJ6eHUBQBgWLVqkxo0b64477vAdBSmA4gwAFfjkk0/05ptvqmPHjjIz33GQAlgQBgDl+OSTT9SxY0edeeaZvqMghdA5A0AZPv/8c82bN08tWrTwHQUphs4ZAErxn//8R6eddppOO+0031GQguicE1xWVpYyMzOVmZkZlUN3Aqlo4cKF2rx5s5o3b+47ClIUxTnBhR5Pm2NgA9X373//W3Xr1uXIX/CKae0kUNbxtAFUzoYNG1SjRg0dd9xxvqMgxdE5A4CkJ554QmvWrFGfPn18RwEozgCwdetWHX300erevbvvKIAkprUBpLhHHnlEJ598snr16uU7CnAQxTnBZGVlKTs7++Dl3NxcZWRk+AsEJLC1a9eqR48e6tGjh+8owCGY1k4woauzJVZoA1V133336dtvv6UwIy7ROScgVmcDVeec01dffaW+ffuqbdu2vuMApaJzBpBS7r//fhUUFFCYEdfonAGkhOLiYr3xxhu6+eabddhhh/mOA5SLzhlASnj00UfVrl07CjMSAp0zgKRWVFSkxx9/XDfeeCPnYkbCoDjHgZJfjyoPX50CKueFF15QZmYmhRkJhWntOFDy61Hl4atTQHjy8/M1atQo9e7dWx07dvQdB6gUOuc4wdejgMgpLi7WJ598ov79+6tGDXoQJB5etQCSyt69ezVgwAD17NlTxxxzjO84QJXQOQNIGnv27NGiRYs0ePBgVmUjodE5A0gKO3fu1KBBg9S+fXu1atXKdxygWuicASS87du3a9WqVRo1apSaNm3qOw5QbXTOABJaXl6ehg0bpjZt2qh58+a+4wARQecMIGFt3rxZq1ev1tixY5WWluY7DhAxdM4AEtLevXs1atQodejQgcKMpEPnDCDhrF+/XosWLdKECRNUu3Zt33GAiKNzBpBQiouL9fDDD+vUU0+lMCNp0TkDSBirVq3SjBkzdP/99/uOAkRVWJ2zmZ1vZkvMbJmZDS1jmyvMbKGZLTCz8M7iAACV8Oqrr+rSSy/1HQOIugo7ZzOrKelRSb+UtFbSLDOb6pxbGLJNB0nDJP2fc26bmR0ZrcAAUs+SJUv0wQcfaODAgb6jADERTud8iqRlzrkVzrl8Sc9LurjENn+Q9KhzbpskOed+iGxMAKmqqKhIc+bM0Z/+9CffUYCYCac4t5K0JuTy2uB1oY6XdLyZTTezGWZ2fqQCAkhdc+fOVXZ2tvr06aNatVgig9QRqVd7LUkdJGVKai1pmpmd7JzLC93IzK6XdL0ktWjR4pBTJO7atStlT5mYl5cnSVF9/qk8vrHA+Ebe9u3btXLlSl188cWMbRTx2o2e6oxtOMV5naQ2IZdbB68LtVbSl865AkkrzWypAsV6VuhGzrksSVmS1K1bN5eZmXnwtpycHIVeTjZZWVnKzi59ndyqVauUkZER1eef7OPrG+MbWTNnztTHH3+s0aNHM7ZRxvhGT3XGNpxp7VmSOpjZMWZWR1JvSVNLbPO6Al2zzKyZAtPcK6qUKEllZ2crNze31NsyMjLUt2/f2AYC4tSCBQuUlpamUaNG+Y4CeFNh5+ycKzSzGyW9J6mmpKeccwvM7C5Js51zU4O3nWtmCyUVSRrknNsSzeCJKCMjg+kjoBzTp0/XtGnTNHToUJmZ7ziAN2Htc3bOvS3p7RLXjQz52UkaGPwHAJU2bdo0HX/88TrttNMozEh5HL4TgHezZ8/WnDlzdNRRR1GYAVGcAXj2xhtvqGXLlrrlllt8RwHiBsU5irKyspSZmanMzMwyF4MBqWz58uVav369WrZs6TsKEFcozlEUukKbFdnAoV544QXt379f119/ve8oQNzhkDtRxgpt4Me2bNmiwsJCderUyXcUIC5RnAHE1OTJk5Wenq4rr7zSdxQgbjGtDSBmtm/frubNm6tnz56+owBxjc4ZQExMmjRJ6enp6tWrl+8oQNyjOAOIujVr1qh79+7q3r277yhAQmBaG0BUPfTQQ1q8eDGFGagEOmcAUeGc08yZM9W7d2+1alXyFPAAykPnDCAqxo8fr8LCQgozUAV0zgAiyjmn1157TTfccIPq1avnOw6QkOicAURUVlaW2rVrR2EGqoHOGUBEFBUVadKkSbrxxhs5sxRQTRTnCMrKylJ2dvbBy7m5ucrIyPAXCIihV199VWeddRaFGYgAprUjKPREFxInu0BqKCgo0IgRI3TJJZfopJNO8h0HSAp0zhHGiS6QSoqLizV9+nT1799ftWrxdgJECp0zgCrZt2+fBgwYoJ/97GdKT0/3HQdIKnzUBVBpe/fu1ZIlS3TbbbepQYMGvuMASYfOGUCl7N69W4MGDVLLli3Vpk0b33GApERxrqasrCxlZmYqMzPzkMVgQDLauXOnli9frhEjRujII4/0HQdIWhTnagpdoc3qbCSznTt3aujQoWrZsqVatGjhOw6Q1NjnHAGs0Eay27p1q1asWKF7771XaWlpvuMASY/OGUC58vPzNXLkSHXo0IHCDMQInTOAMm3cuFG5ubl6+OGH+R4zEEN0zgBK5ZzTI488op49e1KYgRjj/7hK4vjZSAVr1qxRTk6OxowZ4zsKkJLonCuJ42cjFbz++uu6/PLLfccAUhadcxWwOhvJavny5Zo6daoGDBjgOwqQ0uicAUgKnF1qzpw5uvHGG31HAVIenTMALViwQC+++KJGjx7tOwoA0TkDKe+HH35QXl6eRo4c6TsKgCCKM5DCvvrqKz3yyCM67bTTVLNmTd9xAARRnIEUNX/+fDVo0EB33323zMx3HAAhKM5ACpo5c6Zef/11dejQgcIMxCGKM5BiPv30U7Vu3Vp33HEHhRmIUxRnIIXMnTtXM2fOVMuWLSnMQByjOAMp4u2331ZaWppuvfVW31EAVIDvOZei5PGzQ3EsbSSiNWvWaNWqVfrVr37lOwqAMNA5l6Lk8bNDcSxtJJqXX35ZW7Zs0V/+8hffUQCEic65DBw/G8lg+/bt2rt3L7M9QIKhOANJ6plnnlGrVq109dVX+44CoJKY1gaS0I4dO9S0aVOdddZZvqMAqAI6ZyDJPPbYY2rdurV69erlOwqAKqI4A0nku+++U7du3fSzn/3MdxQA1cC0NpAkJk6cqIULF1KYgSRA5wwkOOecPv/8c11xxRU6+uijfccBEAF0zkCCe+SRR1RYWEhhBpIInTOQoJxzeumll/SnP/1JdevW9R0HQATROQMJ6umnn1a7du0ozEASonMGEkxxcbEeeeQR3XzzzZxZCkhSKVucObkFEtWbb76ps846i8IMJLGUndbm5BZINIWFhRoxYoTOO+88/eQnP/EdB0AUpWznLHFyCySOoqIizZw5U1dffTX7mIEUkLKdM5Ao8vPzddttt+nEE0/U8ccf7zsOgBhI6c4ZiHf79u3T0qVLdcstt6hx48a+4wCIETpnIE7t2bNHgwYNUvPmzdWuXTvfcQDEEJ0zEId2796t5cuX6/bbb+fIX0AKonMG4szu3bs1ePBgHXXUURRmIEXROQNxJC8vT0uWLNG9996rtLQ033EAeELnDMSJwsJCjRw5UscffzyFGUhxdM5AHNi0aZO+/PJLTZgwQTVr1vQdB4BndM6AZ845/f3vf1dmZiaFGYAkOmfAq3Xr1um9997T6NGjfUcBEEfonAFPnHOaOnWq+vTp4zsKgDhD5wx4sHLlSr3wwgsaOnSo7ygA4hCdMxBj+/fvV25urgYOHOg7CoA4RXEGYmjRokUaPXq0LrnkEtWpU8d3HABxiuIMxMiGDRu0fft23X333b6jAIhzFGcgBnJzczVx4kSdcsopfF0KQIUozkCUzZ8/X/Xr19eYMWNUowb/ywGoGO8UQBTNmTNHL7/8stLT0ynMAMLGuwUQJdOnT1ezZs105513ysx8xwGQQCjOQBQsXrxYn332mdq0aUNhBlBpFGcgwt5//33VqFFDQ4YMoTADqJKwirOZnW9mS8xsmZmVeUgjM7vMzJyZdYtcRCBxbNy4UYsXL9bxxx/vOwqABFZhcTazmpIelXSBpE6S+phZp1K2ayDpZklfRjokkAhef/11rVq1SjfddJPvKAASXDid8ymSljnnVjjn8iU9L+niUra7W9L9kvZFMB+QEPbu3asdO3aoR48evqMASALhFOdWktaEXF4bvO4gM+sqqY1z7q0IZgMSwnPPPad58+apX79+vqMASBLVPiuVmdWQNF7SNWFse72k6yWpRYsWysnJOXjbrl27DrkcbXl5eZIU08f0Kdbjmyp2796t7777Tp07d2Z8o4TXbnQxvtFTnbENpzivk9Qm5HLr4HUHNJDUWVJOcGXqUZKmmtlFzrnZoXfknMuSlCVJ3bp1c5mZmQdvy8nJUejlaGvUqJEkxfQxfYr1+KaCp556Sk2aNNHQoUMZ3yhibKOL8Y2e6oxtOMV5lqQOZnaMAkW5t6S+B250zm2X1OzAZTPLkXRbycIMJJMVK1aoa9euysjI8B0FQBKqsDg75wrN7EZJ70mqKekp59wCM7tL0mzn3NRoh4yErKwsZWdnH7ycm5vLGyuq5NFHH1Xbtm3161//2ncUAEkqrH3Ozrm3Jb1d4rqRZWybWf1YkZednX1IQc7IyFDfvn3L/yWghE8//VSXX365jjzySN9RACSxai8ISyQZGRksfECV/eMf/9AJJ5xAYQYQdSlVnIGqcM7p+eef13XXXafatWv7jgMgBXBsbaAC2dnZat++PYUZQMzQOQNlKC4u1sMPP6ybb75ZNWvW9B0HQAqhcwbK8P777+sXv/gFhRlAzFGcgRKKioo0fPhwnXHGGerSpYvvOABSEMUZCFFUVKQ5c+boyiuv1OGHH+47DoAURXEGggoKCjRo0CC1a9dOJ554ou84AFIYC8IASfv379e3336rG2+8ke8xA/COzhkpb9++fRo0aJAaNWqkY4891nccAEiuzrnk8bNDcSxtlGbPnj1atmyZhg4dqpYtW/qOAwCSkqxzPnD87NJwLG2UtG/fPg0ePFhHHnkkhRlAXEmqzlni+NkIz44dOzRv3jzde++9atiwoe84AHCIpOqcgXAUFxdrxIgR6tixI4UZQFxKus4ZKM+WLVs0bdo0TZgwQTVq8NkUQHzi3QkpZdKkSTr77LMpzADiGp0zUsKGDRv0n//8RyNGjPAdBQAqRPuApOec0xtvvKGrr77adxQACAudM5Lad999pylTptAxA0godM5IWvv27dPcuXM1ePBg31EAoFIozkhKS5cu1ciRI3XhhReqbt26vuMAQKVQnJF0vv/+e23fvl333nuvzMx3HACotIQvzllZWcrMzFRmZmaZh+5E6pg3b54mTpyorl27qlYtllQASEwJX5xDj6fN8bNT2/z581WvXj2NHTtWNWvW9B0HAKosKVoLjqeN+fPn68UXX9SoUaM4wAiAhMe7GBLeF198ofr162v06NEUZgBJgXcyJLQVK1bo448/Vvv27Vn8BSBpUJyRsP773/9qz549GjZsGIUZQFKhOCMhbd26VfPnz1fnzp0pzACSTlIsCENqefPNN5WWlqabb77ZdxQAiAo6ZySUffv2aevWrTr99NN9RwGAqKFzRsJ48cUXVa9ePfXr1893FACIKoozEsKOHTvUsGFDnX/++b6jAEDUUZwR9/71r3/p8MMP1+WXX+47CgDEBMUZce3bb79V165ddfLJJ/uOAgAxw4IwxK3HHntMCxcupDADSDl0zohLH3/8sS677DI1a9bMdxQAiDk6Z8SdJ554QgUFBRRmACmLzhlxwzmnZ599Vtdccw3nYgaQ0uicETdefvlltW/fnsIMIOXxLgjvnHMaP368brrpJtWuXdt3HADwjs4Z3n388cc688wzKcwAEERxhjfFxcUaPny4unXrpm7duvmOAwBxg2lteFFUVKR58+apd+/eatiwoe84ABBX6JwRcwUFBRoyZIiaN2+uzp07+44DAHGHzhkxlZ+fr2XLlumPf/yjWrVq5TsOAMQlOmfEzP79+zV48GAdfvjh6tChg+84ABC36JwRE3v37tXSpUs1aNAgOmYAqACdM6KuoKBAgwYNUrNmzSjMABAGOmdE1c6dOzVnzhyNHTtWDRo08B0HABICnTOixjmnUaNGqVOnThRmAKgEOmdExbZt2/TBBx9o3LhxqlGDz4AAUBm8ayIqsrKydO6551KYAaAKEq5zzsrKUnZ29sHLubm5ysjI8BcIh/jhhx/04osvasiQIb6jAEDCSri2Jjs7W7m5uQcvZ2RkqG/fvv4C4SDnnN566y397ne/8x0FABJawnXOUqAg5+Tk+I6BEGvXrlVWVpbuuusu31EAIOElXOeM+LN3717Nnz9ft99+u+8oAJAUKM6oluXLl+uOO+7Qeeedp3r16vmOAwBJgeKMKlu7dq22b9+u+++/X2bmOw4AJA2KM6pk0aJFeuSRR/STn/xEtWvX9h0HAJIKxRmVtmDBAtWqVUtjx45VrVoJuaYQAOIaxRmVsnjxYmVnZ+u4445TzZo1fccBgKREcUbYZs6cqZo1a+qee+7hyF8AEEW8wyIsa9eu1bvvvqv09HQWfwFAlLHDEBX65JNP1KBBA40YMYLCDAAxQOeMcu3cuVNff/21unTpQmEGgBihc0aZ3nnnHdWuXVu33HKL7ygAkFLonFGq/Px8bdq0Seecc47vKACQcuic8SOvvvqqiouL1a9fP99RACAlUZxxiO3bt+uII47Queee6zsKAKQsijMOevbZZ1WjRg3Ojw0AnlGcISlw5K+uXbuqU6dOvqMAQMqLy+KclZWl7OzsUm/Lzc1VRkZGbAMluSeffFKNGjXSZZdd5jsKAEBxWpyzs7PLLMIZGRlMu0bQf//7X11yySVq0qSJ7ygAgKC4LM5SoAjn5OT4jpHUpkyZombNmlGYASDOxG1xRnRNmTJFffv25ZSPABCHOAhJCpo6daratm1LYQaAOBVWcTaz881siZktM7Ohpdw+0MwWmtlcM/uvmbWLfFRUl3NODz30kM477zxlZmb6jgMAKEOFxdnMakp6VNIFkjpJ6mNmJb9v87Wkbs65n0h6WdIDkQ6K6ps+fbp69uypunXr+o4CAChHOJ3zKZKWOedWOOfyJT0v6eLQDZxzHzvn9gQvzpDUOrIxUR3FxcV66qmndOKJJ6pHjx6+4wAAKhDOTsdWktaEXF4rqbx3+GslvVPaDWZ2vaTrJalFixaHrMbetWvXwct5eXmSxGrtCCgqKtLq1avVvXt3zZs3z3ecpBX6+kVkMbbRxfhGT3XGNqIrgszsKkndJJ1Z2u3OuSxJWZLUrVs3F7rfMycn5+B+0EaNGkkS+0WrqbCwULfffrtuuOEGrVy5kvGMotDXLyKLsY0uxjd6qjO24Uxrr5PUJuRy6+B1hzCzcyTdIeki59z+KqVBxBQUFGjZsmW69tpr1a4d6/MAIJGEU5xnSepgZseYWR1JvSVNDd3AzLpIekyBwvxD5GOiMvLz8zV48GDVrl1bJ5xwgu84AIBKqnBa2zlXaGY3SnpPUk1JTznnFpjZXZJmO+emShon6QhJL5mZJK12zl0UboisrCxNmjTp4HQ2x8+uun379mnx4sW67bbb1KpVK99xAABVENb3nJ1zbzvnjnfOHeecGxO8bmSwMMs5d45zroVzLiP4L+zCLAWOpb1s2bKDlzl+dtUUFRVp8ODBatq0KYUZABJY3BwiKj09nRWD1bB7927NmDFDY8eOVf369X3HAQBUA4fvTBJ33XWXOnfuTGEGgCQQN50zqiYvL09vvfWW7rvvPgX39wMAEhydc4J78skndcEFF1CYASCJ0DknqM2bN2vKlCm69dZbfUcBAEQYnXMCcs7p3Xff1R/+8AffUQAAUUBxTjDff/+9br/9dl111VVq0KCB7zgAgCigOCeQ3bt3a+HChRo5cqTvKACAKKI4J4hVq1bp9ttv11lnnaXDDjvMdxwAQBRRnBPA2rVrlZeXp3HjxqlGDf5kAJDseKePc0uXLtWECRN00kknqU6dOr7jAABigOIcxxYuXChJuv/++1W7dm3PaQAAsUJxjlPLly/XlClTdNxxx6lWLb6ODgCphOIch7766ivt379f9957r2rWrOk7DgAgxijOceaHH37QG2+8oRNPPJHFXwCQopgvjSOfffaZatWqpVGjRvmOAgDwiNYsTuzdu1ezZs1Sjx49fEcBAHhG5xwHPvjgA+Xn52vAgAG+owAA4gCds2cFBQXauHGjevXq5TsKACBO0Dl7NHXqVO3atUtXXXWV7ygAgDhCcfZk27Ztql+/vi666CLfUQAAcYbi7MHzzz+v/Px89evXz3cUAEAcojjH2IIFC9SlSxedcMIJvqMAAOIUC8JiaMqUKVqwYAGFGQBQLjrnGHn//fd18cUXKy0tzXcUAECco3OOgeeff1779++nMAMAwkLnHGWTJ0/WlVdeySkfAQBho3OOonfffVetW7emMAMAKoXOOQqcc3rooYf05z//WfXr1/cdBwCQYOicI8w5p1mzZunnP/85hRkAUCUU5wgqLi7WnXfeqbZt2+r//u//fMcBACQoinOEFBcXa+nSpfrNb36jo446ynccAEACozhHQFFRkYYNG6ZatWqpa9euvuMAABIcC8KqqbCwUMuXL9fvfvc7paen+44DAEgCdM7VUFBQoMGDB8vM1LFjR99xAABJgs65ivbv368FCxbo1ltvVatWrXzHAQAkETrnKiguLtaQIUPUtGlTCjMAIOLonCtpz549mjZtmsaOHavDDjvMdxwAQBKic66kMWPG6Kc//SmFGQAQNXTOYdqxY4dee+013XPPPTIz33EAAEmMzjlMTz/9tHr16kVhBgBEHZ1zBbZu3aonnnhCgwcP9h0FAJAi6JzLUVxcrA8++EB//OMffUcBAKQQinMZNmzYoCFDhuiKK65QWlqa7zgAgBRCcS7Fzp07tXjxYo0aNYp9zACAmKM4l7B69Wrdfvvt6tmzJ+djBgB4QXEOsWbNGuXl5enBBx9UrVqslQMA+EFxDlq+fLkmTJigjh07qm7dur7jAABSGO2hpMWLF0uS7r//ftWuXdtzGgBAqkv5znn16tV6+umn1aFDBwozACAupHTnnJubqxo1amjs2LGqUSPlP6cAAOJEylakvLw8vfbaa+rcuTOFGQAQV1Kyc54xY4by8/M1evRo31EAAPiRlGsZ8/Pz9cUXX+j000/3HQUAgFKlVOf80UcfKS8vTwMGDPAdBQCAMqVM51xQUKD169fr0ksv9R0FAIBypUTn/NZbb2nTpk265pprfEcBAKBCSV+cN2/erPr166tXr16+owAAEJakLs4vvfSSdu7cqd///ve+owAAELakLc5z585Vly5dlJ6e7jsKAACVkpQLwp577jnNmzePwgwASEhJ1zm/88476tWrlxo2bOg7CgAAVZJUxfmVV15RjRo1KMwAgISWNMV58uTJ6tOnD+diBgAkvKTY5/zRRx/pqKOOojADAJJCQnfOzjmNHz9e1113ndLS0nzHAQAgIhK2c3bOae7cuerevTuFGQCQVBKyODvndPfdd6tx48Y644wzfMcBACCiEm5au7i4WCtWrNAFF1ygtm3b+o4DAEDEJVTnXFxcrOHDh6ugoEDdu3f3HQcAgKhImM65qKhIy5cv11VXXaUTTzzRdxwAAKImITrnwsJCDRkyREVFRerUqZPvOAAARFXcd84FBQX65ptvdOutt+roo4/2HQcAgKiL687ZOaehQ4eqSZMmFGYAQMqI28553759+vDDDzVmzBjVq1fPdxwAAGImbjvnBx54QF26dKEwAwBSTljF2czON7MlZrbMzIaWcntdM3shePuXZta+qoF27dqlJ598UiNGjFCrVq2qejcAACSsCouzmdWU9KikCyR1ktTHzEoumb5W0jbnXLqkCZLur2qgZ555RhdddJHMrKp3AQBAQguncz5F0jLn3ArnXL6k5yVdXGKbiyX9K/jzy5LOtkpW18LCQo0ZM0Z//vOf1bx588r8KgAASSWc4txK0pqQy2uD15W6jXOuUNJ2SU0rE2TXrl264YYbKvMrAAAkpZiu1jaz6yVdL0ktWrRQTk6OJKlZs2ZKS0tTbm5uLOOklF27dh0cb0Qe4xs9jG10Mb7RU52xDac4r5PUJuRy6+B1pW2z1sxqSUqTtKXkHTnnsiRlSVK3bt1cZmamJCkzM1M5OTk6cBmRx/hGF+MbPYxtdDG+0VOdsQ1nWnuWpA5mdoyZ1ZHUW9LUEttMldQ/+PNvJX3knHNVSgQAQIqrsHN2zhWa2Y2S3pNUU9JTzrkFZnaXpNnOuamSnpT0jJktk7RVgQIOAACqwHw1uGa2SdJ3IVc1k7TZS5jUwPhGF+MbPYxtdDG+0VNybNs558L6OpK34lySmc12znXznSNZMb7RxfhGD2MbXYxv9FRnbOP28J0AAKQqijMAAHEmnopzlu8ASY7xjS7GN3oY2+hifKOnymMbN/ucAQBAQDx1zgAAQB6KcyxPP5mKwhjfgWa20Mzmmtl/zaydj5yJqKKxDdnuMjNzZsYK2EoIZ3zN7Irg63eBmWXHOmOiCuN9oa2ZfWxmXwffG37lI2ciMrOnzOwHM5tfxu1mZo8Ex36umXUN646dczH7p8BBTJZLOlZSHUnfSOpUYpu/SPpn8Ofekl6IZcZE/hfm+P5C0uHBn//M+EZubIPbNZA0TdIMSd18506Uf2G+djtI+lpS4+DlI33nToR/YY5tlqQ/B3/uJGmV79yJ8k/SGZK6Sppfxu2/kvSOJJN0qqQvw7nfWHfOMTn9ZAqrcHydcx875/YEL85Q4FjpqFg4r11JuluB85nvi2W4JBDO+P5B0qPOuW2S5Jz7IcYZE1U4Y+skNQz+nCbp+xjmS2jOuWkKHBmzLBdLmuICZkhqZGZHV3S/sS7OMTn9ZAoLZ3xDXavAJzpUrMKxDU5XtXHOvRXLYEkinNfu8ZKON7PpZjbDzM6PWbrEFs7YjpJ0lZmtlfS2pL/GJlpKqOz7sqQYnzIS8cPMrpLUTdKZvrMkAzOrIWm8pGs8R0lmtRSY2s5UYMZnmpmd7JzL8xkqSfSRNNk595CZ/VyBcyV0ds4V+w6WqmLdOVfm9JMq7/STKFU44yszO0fSHZIucs7tj1G2RFfR2DaQ1FlSjpmtUmDf0lQWhYUtnNfuWklTnXMFzrmVkpYqUKxRvnDG9lpJL0qSc+4LSfUUOC40qi+s9+WSYl2cOf1kdFU4vmbWRdJjChRm9tmFr9yxdc5td841c861d861V2B//kXOudl+4iaccN4bXlega5aZNVNgmntFDDMmqnDGdrWksyXJzE5UoDhvimnK5DVVUr/gqu1TJW13zq2v6JdiOq3tOP1kVIU5vuMkHSHppeA6u9XOuYu8hU4QYY4tqijM8X1P0rlmtlBSkaRBzjlm1SoQ5tjeKulxMxugwOKwa2iKwmNmzynwobFZcJ/9nZJqS5Jz7p8K7MP/laRlkvZI+l1Y98v4AwAQXzhCGAAAcYbiDABAnKE4AwAQZyjOAADEGYozAABxhuIMAECcoTgDABBnKM4AAMSZ/w9AzgaDlQHsXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f931979ecd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4567 - accuracy: 0.7726 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4565 - accuracy: 0.7726 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4563 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4562 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.7726 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4558 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4556 - accuracy: 0.7726 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4553 - accuracy: 0.7708 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4552 - accuracy: 0.7708 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4550 - accuracy: 0.7726 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4548 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4545 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4544 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4542 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4541 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4540 - accuracy: 0.7726 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4538 - accuracy: 0.7726 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7726 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4535 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4534 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4533 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4531 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4530 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4529 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4527 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4525 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4524 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4522 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4521 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4520 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4518 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4517 - accuracy: 0.7743 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4515 - accuracy: 0.7726 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4514 - accuracy: 0.7743 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4513 - accuracy: 0.7743 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.7743 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4511 - accuracy: 0.7726 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4510 - accuracy: 0.7743 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.7743 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4508 - accuracy: 0.7760 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4507 - accuracy: 0.7743 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.7760 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4505 - accuracy: 0.7743 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.7743 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4503 - accuracy: 0.7743 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.7760 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.7760 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4500 - accuracy: 0.7760 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4499 - accuracy: 0.7760 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4498 - accuracy: 0.7760 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4496 - accuracy: 0.7778 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4495 - accuracy: 0.7778 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4494 - accuracy: 0.7778 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4493 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4489 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4488 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4487 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4487 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4486 - accuracy: 0.7760 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.7778 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4484 - accuracy: 0.7778 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.7778 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4477 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4477 - accuracy: 0.7760 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4476 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4474 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4473 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4472 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4472 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4469 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4468 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4467 - accuracy: 0.7795 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4466 - accuracy: 0.7795 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4464 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4463 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4462 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4461 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4459 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4458 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4457 - accuracy: 0.7795 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.7778 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4456 - accuracy: 0.7778 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4455 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4454 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4453 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4452 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4451 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4451 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4450 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4449 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4448 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.7795 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4444 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.7812 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4443 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4438 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4438 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4437 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4435 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7830 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.7830 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4419 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.7795 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4416 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4415 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4414 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4413 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4413 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4412 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4411 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4408 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4405 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4405 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4400 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7795 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4398 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4397 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4396 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4396 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4395 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4394 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4394 - accuracy: 0.7795 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4393 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4393 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4392 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4391 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4389 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7778 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4386 - accuracy: 0.7778 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4386 - accuracy: 0.7778 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4385 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4384 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4384 - accuracy: 0.7795 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4384 - accuracy: 0.7778 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4383 - accuracy: 0.7778 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.7795 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.7795 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4381 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4379 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4377 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4377 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.7812 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4372 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4372 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4371 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4371 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4370 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.7847 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.7847 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.7847 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.7847 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4366 - accuracy: 0.7830 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4364 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4363 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4360 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4357 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4348 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7500\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4339 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7500\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4326 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4326 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4325 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4325 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4324 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4324 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4324 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4323 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4323 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7500\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4322 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4321 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4318 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4317 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4317 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4315 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4315 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4315 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4314 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4314 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4313 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4313 - accuracy: 0.7830 - val_loss: 0.5017 - val_accuracy: 0.7552\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4312 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4312 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4311 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4311 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7552\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4306 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4305 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.7865 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.5019 - val_accuracy: 0.7552\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4303 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4303 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.7865 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4299 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5021 - val_accuracy: 0.7552\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.7882 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4296 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7552\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7500\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4295 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7500\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5022 - val_accuracy: 0.7500\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4293 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7500\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7448\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7448\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5024 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7448\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.7882 - val_loss: 0.5026 - val_accuracy: 0.7448\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4280 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.7882 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5027 - val_accuracy: 0.7448\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4277 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5028 - val_accuracy: 0.7448\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7448\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4273 - accuracy: 0.7917 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.7899 - val_loss: 0.5029 - val_accuracy: 0.7500\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4272 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7917 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7917 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4269 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7500\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4269 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4268 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4267 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4266 - accuracy: 0.7969 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4266 - accuracy: 0.7969 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.5031 - val_accuracy: 0.7500\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4265 - accuracy: 0.7969 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4264 - accuracy: 0.7969 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.7969 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4264 - accuracy: 0.7969 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4263 - accuracy: 0.7969 - val_loss: 0.5032 - val_accuracy: 0.7500\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4263 - accuracy: 0.7969 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4263 - accuracy: 0.7969 - val_loss: 0.5032 - val_accuracy: 0.7448\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4262 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7448\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.5034 - val_accuracy: 0.7448\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5035 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5035 - val_accuracy: 0.7448\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5036 - val_accuracy: 0.7448\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7448\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4250 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4250 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4250 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4250 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.7986 - val_loss: 0.5038 - val_accuracy: 0.7448\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4248 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7448\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4248 - accuracy: 0.7986 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4248 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.7969 - val_loss: 0.5039 - val_accuracy: 0.7396\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4247 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5040 - val_accuracy: 0.7396\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7396\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5041 - val_accuracy: 0.7448\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.5042 - val_accuracy: 0.7448\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5043 - val_accuracy: 0.7448\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.5044 - val_accuracy: 0.7448\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.5045 - val_accuracy: 0.7448\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7448\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4233 - accuracy: 0.7951 - val_loss: 0.5047 - val_accuracy: 0.7448\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.7951 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4231 - accuracy: 0.7951 - val_loss: 0.5048 - val_accuracy: 0.7448\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4230 - accuracy: 0.7951 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5049 - val_accuracy: 0.7448\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.7951 - val_loss: 0.5050 - val_accuracy: 0.7448\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4227 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4226 - accuracy: 0.7951 - val_loss: 0.5051 - val_accuracy: 0.7448\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4225 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5052 - val_accuracy: 0.7448\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4224 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7448\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7448\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.7934 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.7934 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4217 - accuracy: 0.7934 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.7934 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.7934 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4215 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4209 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4208 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4207 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4199 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4197 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4194 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4193 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4192 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4190 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4188 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.7951 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4180 - accuracy: 0.7951 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4178 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4175 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4171 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.7969 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4166 - accuracy: 0.7969 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5077 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4164 - accuracy: 0.7986 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4162 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4158 - accuracy: 0.7986 - val_loss: 0.5082 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9318ef9940>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6gAAAHSCAYAAADhZ+amAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABUMElEQVR4nO3deXzV5Z33/9eVhM0dATewKg5akZ0IHtcgXRy1IHWpS4vUjlTndoFO1W5THRyrtN63y0yt+9bxJ2PbEXHU2pY2atu4gKIIalXEClYrKIgiZDnX749zEk5CEs5JTnJOktfz8cic811znfQ7MW8+1xJijEiSJEmSVGglhW6AJEmSJElgQJUkSZIkFQkDqiRJkiSpKBhQJUmSJElFwYAqSZIkSSoKBlRJkiRJUlEoK3QDmho4cGDcd999C90MSZIkSVIHWLx48ZoY46DmjhVdQN13331ZtGhRoZshSZIkSeoAIYS3WjpmF19JkiRJUlEwoEqSJEmSikJWATWEcGwI4dUQwushhO80c/zaEMKS9NdfQgjrMo6dFUJ4Lf11Vh7bLkmSJEnqRrY5BjWEUAr8FPg8sAp4NoSwIMa4vP6cGOPsjPMvAMam3+8KXAaUAxFYnL72w7x+CkmSJEntVlNTw6pVq9i0aVOhm6JuoG/fvgwZMoRevXplfU02kyRNAF6PMa4ACCHMA6YCy1s4/3RSoRTgi8BvY4wfpK/9LXAscF/WLZQkSZLUKVatWsWOO+7IvvvuSwih0M1RFxZjZO3ataxatYr99tsv6+uy6eI7GHg7Y3tVet9WQgj7APsBv8/l2hDCzBDCohDCovfffz+bdkuSJEnKs02bNjFgwADDqdothMCAAQNyrsbne5Kk04BfxhjrcrkoxnhLjLE8xlg+aFCzy+FIkiRJ6gSGU+VLW56lbALqamDvjO0h6X3NOY3G3XdzuVaSJElSD7Z27VrGjBnDmDFj2GOPPRg8eHDDdnV1davXLlq0iAsvvDCn77fvvvuyZs2a9jS5zVauXEm/fv0YM2YMw4cPZ/r06dTU1OTl3t///vfZe++92WGHHfJyv86UTUB9FhgWQtgvhNCbVAhd0PSkEMJngf5AVcbux4AvhBD6hxD6A19I75MkSZKkRgYMGMCSJUtYsmQJ5557LrNnz27Y7t27N7W1tS1eW15ezg033NCJrW2//fffnyVLlrB06VJWrVrF/fffn5f7fulLX+KZZ57Jy7062zYDaoyxFjifVLB8Gbg/xrgshDAnhDAl49TTgHkxxphx7QfAFaRC7rPAnPoJkyRJkiR1A1VVcNVVqdcOMGPGDM4991wmTpzIJZdcwjPPPEMikWDs2LEcdthhvPrqqwBUVlZywgknAHD55Zdz9tlnU1FRwdChQ3MKritXruSYY45h1KhRTJ48mb/+9a8A/OIXv2DEiBGMHj2ao446CoBly5YxYcIExowZw6hRo3jttdfa9BlLS0uZMGECq1enOptmVnYXLVpERUVFTp/r0EMPZc8992xTWwotm1l8iTE+AjzSZN8Pm2xf3sK1dwB3tLF9kiRJkgph1ixYsqT1c9avhxdfhGQSSkpg1CjYeeeWzx8zBq67LuemrFq1ij//+c+Ulpby0Ucf8eSTT1JWVsbvfvc7vve97/GrX/1qq2teeeUV/vCHP7BhwwYOPPBAzjvvvKyWO7ngggs466yzOOuss7jjjju48MILmT9/PnPmzOGxxx5j8ODBrFu3DoCbbrqJiy66iDPPPJPq6mrq6nKaiqfBpk2bePrpp7n++uu3eW5bP1dXke9JkiRJkiT1FOvXp8IppF7Xr++Qb3PKKadQWlqa/pbrOeWUUxgxYgSzZ89m2bJlzV5z/PHH06dPHwYOHMhuu+3Ge++9l9X3qqqq4owzzgDga1/7Gn/84x8BOPzww5kxYwa33nprQxBNJBL86Ec/Yu7cubz11lv069cvp8/1xhtvMGbMGHbffXf23HNPRo0atc1r2vq5uoqsKqiSJEmSephsKp1VVTB5MlRXQ+/ecO+9kEjkvSnbb799w/t//dd/ZdKkSTzwwAOsXLmyoftrU3369Gl4X1pa2ur41WzcdNNNPP300zz88MOMHz+exYsXc8YZZzBx4kQefvhhjjvuOG6++WaOOeaYhmseeOAB/u3f/g2A2267jfLy8kb3rB+DumbNGg4//HAWLFjAlClTKCsrI5kO/k2Xacn35yo2VlAlSZIktU0iAQsXwhVXpF47IJw2tX79egYPHgzAXXfdlff7H3bYYcybNw+Ae++9lyOPPBJIVTsnTpzInDlzGDRoEG+//TYrVqxg6NChXHjhhUydOpUXX3yx0b2mTZvWMMlT03CaaeDAgVx99dVcddVVQGoM6uLFiwGa7b7cnRlQJUmSJLVdIgHf/W6nhFOASy65hO9+97uMHTs2L9XDUaNGMWTIEIYMGcK3vvUt/uM//oM777yTUaNG8fOf/7xhXOjFF1/MyJEjGTFiBIcddhijR4/m/vvvZ8SIEYwZM4aXXnqJ6dOnt7kdJ554Ihs3buTJJ5/ksssu46KLLqK8vLyha3MuLrnkEoYMGcLGjRsZMmQIl19+eZvb1dlCxqS7RaG8vDwuWrSo0M2QJEmSepyXX36Zgw46qNDNUDfS3DMVQlgcY2y2pGwFNVeVlfDDH3bYNNqSJEmS1FM5SVIu6geBJ5NwzTWd1s9ekiRJknoCK6i5qKzcMo12dXVqW5IkSZKUFwbUXFRUQP0g5d69U9uSJEmSpLwwoOYikYBTT4WyMrv3SpIkSVKeGVBzNXw41NbCuHGFbokkSZIkdSsG1Fztskvqdf36gjZDkiRJ6m7Wrl3LmDFjGDNmDHvssQeDBw9u2K6urm712kWLFnHhhRfm9P323Xdf1qxZ054mt9nKlSvp168fY8aMYfjw4UyfPp2ampp233fjxo0cf/zxfPazn+Xggw/mO9/5Th5a23kMqLnq3z/1um5dQZshSZIkdTcDBgxgyZIlLFmyhHPPPZfZs2c3bPfu3Zva2toWry0vL+eGG27oxNa23/7778+SJUtYunQpq1at4v7778/Lfb/97W/zyiuv8Pzzz/OnP/2JRx99NC/37QwG1FzVV1ANqJIkSRKs+BB+/XrqtQPMmDGDc889l4kTJ3LJJZfwzDPPkEgkGDt2LIcddhivvvoqAJWVlZxwwgkAXH755Zx99tlUVFQwdOjQnILrypUrOeaYYxg1ahSTJ0/mr3/9KwC/+MUvGDFiBKNHj+aoo44CYNmyZUyYMIExY8YwatQoXnvttTZ9xtLSUiZMmMDq1auBxpXdRYsWUZGenDWbz7XddtsxadIkAHr37s24ceNYtWpVm9pVCK6DmisDqiRJknqCXyyDVR+1fs6nNbB6A0QgAIN3hH69Wj5/yE5wysE5N2XVqlX8+c9/prS0lI8++ognn3ySsrIyfve73/G9732PX/3qV1td88orr/CHP/yBDRs2cOCBB3LeeefRq1crbUu74IILOOusszjrrLO44447uPDCC5k/fz5z5szhscceY/DgwaxLZ4GbbrqJiy66iDPPPJPq6mrq6upy/mwAmzZt4umnn+b666/f5rm5fK5169bx0EMPcdFFF7WpXYVgBTVHlX/Zi39lDlXPlBa6KZIkSVJhfVqbCqeQev205S647XHKKadQml7ucf369ZxyyimMGDGC2bNns2zZsmavOf744+nTpw8DBw5kt91247333svqe1VVVXHGGWcA8LWvfY0//vGPABx++OHMmDGDW2+9tSGIJhIJfvSjHzF37lzeeust+vXrl9PneuONNxgzZgy77747e+65J6NGjdrmNdl+rtraWk4//XQuvPBChg4dmlO7CskKag6qqmDyP+1Lkh/wfy+rZuFuS0nMHFnoZkmSJEn5l02lc8WHcP1TUJeE0hL4+lgY2j/vTdl+++0b3v/rv/4rkyZN4oEHHmDlypUN3V+b6tOnT8P70tLSVsevZuOmm27i6aef5uGHH2b8+PEsXryYM844g4kTJ/Lwww9z3HHHcfPNN3PMMcc0XPPAAw/wb//2bwDcdtttlJeXN7pn/RjUNWvWcPjhh7NgwQKmTJlCWVkZyWQSSFVX2/K5Zs6cybBhw5g1a1a7Pndns4Kag8pKSD0ngepkCZX/5xep1CpJkiT1REP7w0WHwgkHpl47IJw2tX79egYPHgzAXXfdlff7H3bYYcybNw+Ae++9lyOPPBJIVTsnTpzInDlzGDRoEG+//TYrVqxg6NChXHjhhUydOpUXX3yx0b2mTZvWMMlT03CaaeDAgVx99dVcddVVQGoM6uLFiwGa7b68LT/4wQ9Yv3491113Xc7XFpoBNQcVFVBaEoFIb2qoSP4+lVolSZKknmpofzj2HzolnAJccsklfPe732Xs2LHtrooCjBo1iiFDhjBkyBC+9a1v8R//8R/ceeedjBo1ip///OcN40IvvvhiRo4cyYgRIzjssMMYPXo0999/PyNGjGDMmDG89NJLTJ8+vc3tOPHEE9m4cSNPPvkkl112GRdddBHl5eUNXZuztWrVKq688kqWL1/OuHHjGDNmDLfddlub29XZQoxx22d1ovLy8rho0aJCN6NFM477O/c8OpAnOZLD+z0PCxdCIlHoZkmSJEnt9vLLL3PQQQcVuhnqRpp7pkIIi2OMzZaUraDmaPTndyNSwvDhwXAqSZIkSXlkQM3RgAGp17UDDjCcSpIkSVIeGVBz1BBQPwiFbYgkSZIkdTMG1Bw1BNT1rtAjSZIkSflkQM1RfUC96/3jXWFGkiRJkvLIgJqjFStSr7/cfDyTJ7sMqiRJkiTliwE1R6n1ciORUqo3J10GVZIkScqTSZMm8dhjjzXad91113Heeee1eE1FRQX1y1Qed9xxrFu3bqtzLr/8cq655ppWv/f8+fNZvnx5w/YPf/hDfve73+XQ+uZVVlZywgkntPs+bXX55ZczePBgxowZw/Dhw7nvvvvyct+1a9cyadIkdthhB84///y83BMMqDmbNHApAIEkvZObqBiwtMAtkiRJkrqH008/nXnz5jXaN2/ePE4//fSsrn/kkUfYZZdd2vS9mwbUOXPm8LnPfa5N9yo2s2fPZsmSJTz44IN885vfpKampt337Nu3L1dcccU2g3+uDKg5Sqz9X/bmrxzMSyws+QKJtf9b6CZJkiRJBVNVBVddlZ+hbyeffDIPP/ww1dXVAKxcuZJ33nmHI488kvPOO4/y8nIOPvhgLrvssmav33fffVmzZg0AV155JQcccABHHHEEr776asM5t956K4cccgijR4/mpJNOYuPGjfz5z39mwYIFXHzxxYwZM4Y33niDGTNm8Mtf/hKAhQsXMnbsWEaOHMnZZ5/N5s2bG77fZZddxrhx4xg5ciSvvPJK1p/1vvvuY+TIkYwYMYJLL70UgLq6OmbMmMGIESMYOXIk1157LQA33HADw4cPZ9SoUZx22mk5/lS3GDZsGNtttx0ffvjhVpXd888/n7vuuivrz7X99ttzxBFH0Ldv3za3pzlORZurigqGhHfoFzeS6LUIKn5S6BZJkiRJeTdrFixZ0vo569fDiy9CMgklJTBqFOy8c8vnjxkD113X8vFdd92VCRMm8OijjzJ16lTmzZvHqaeeSgiBK6+8kl133ZW6ujomT57Miy++yKhRo5q9z+LFi5k3bx5LliyhtraWcePGMX78eAC+/OUvc8455wDwgx/8gNtvv50LLriAKVOmcMIJJ3DyySc3utemTZuYMWMGCxcu5IADDmD69On87Gc/Y9asWQAMHDiQ5557jhtvvJFrrrmG2267rfUfGvDOO+9w6aWXsnjxYvr3788XvvAF5s+fz957783q1at56aWXABq6K1999dW8+eab9OnTp9kuzNl67rnnGDZsGLvttlujanFz2vK58sEKaq4SCQaMHMxaBsAVV0AiUegWSZIkSQWxfn0qnELqdf369t8zs5tvZvfe+++/n3HjxjF27FiWLVvWasB68sknmTZtGttttx077bQTU6ZMaTj20ksvceSRRzJy5Ejuvfdeli1b1mp7Xn31Vfbbbz8OOOAAAM466yyeeOKJhuNf/vKXARg/fjwrV67M6jM+++yzVFRUMGjQIMrKyjjzzDN54oknGDp0KCtWrOCCCy7g17/+NTvttBMAo0aN4swzz+S//uu/KCvLvcZ47bXXcvDBBzNx4kS+//3vZ3VNWz5XPlhBbYMB/9CfJS8G2G23QjdFkiRJ6hCtVTrrVVXB5MlQXQ29e8O997a/fjN16lRmz57Nc889x8aNGxk/fjxvvvkm11xzDc8++yz9+/dnxowZbNq0qU33nzFjBvPnz2f06NHcddddVLZz1tM+ffoAUFpaSm1tbbvu1b9/f1544QUee+wxbrrpJu6//37uuOMOHn74YZ544gkeeughrrzySpYuXdooqH7961/n+eefZ6+99uKRRx7Z6r6zZ8/m29/+NgsWLOAb3/gGb7zxBmVlZSTr/3UBtvp55vNz5cIKahsM3KtXqoL6wQeFbookSZJUMIkELFyY6li4cGF+OhfusMMOTJo0ibPPPruhevrRRx+x/fbbs/POO/Pee+/x6KOPtnqPo446ivnz5/Ppp5+yYcMGHnrooYZjGzZsYM8996SmpoZ77723Yf+OO+7Ihg0btrrXgQceyMqVK3n99dcB+PnPf87RRx/drs84YcIEHn/8cdasWUNdXR333XcfRx99NGvWrCGZTHLSSSfx7//+7zz33HMkk0nefvttJk2axNy5c1m/fj0ff/xxo/vdeeedLFmypNlwmmnKlCmUl5dz9913s88++7B8+XI2b97MunXrWLhwYbs+U75YQW2DT2p68yklVD63ExWFbowkSZJUQIlE/ke9nX766UybNq2hq+/o0aMZO3Ysn/3sZ9l77705/PDDW71+3LhxfOUrX2H06NHstttuHHLIIQ3HrrjiCiZOnMigQYOYOHFiQyg97bTTOOecc7jhhhsaJkeC1Gy1d955J6eccgq1tbUccsghnHvuuTl9noULFzJkyJCG7V/84hdcffXVTJo0iRgjxx9/PFOnTuWFF17g61//ekNl86qrrqKuro6vfvWrrF+/nhgjF154YZtnKobU8jlnnHEG55xzDqeeeiojRoxgv/32Y+zYsTnfa9999+Wjjz6iurqa+fPn85vf/Ibhw4e3uW0AIcbYrhvkW3l5eaxfx6gYVVXB0UdDTQ30La3m90/2dhiqJEmSuoWXX36Zgw46qNDNUDfS3DMVQlgcYyxv7ny7+OaoshLq6lLva+pKaWeXdUmSJElSmgE1RxUV0KtX6n0ZtVQMWFrQ9kiSJElSd2FAzVEiAXd9L7XQ76VcRWLWxPysSixJkiRJPZwBtQ2+WJuaHWsX1qfm1LafryRJkiS1mwG1DXY59lDKqOHv7JZa8KmiotBNkiRJkqQuz4DaBuGwBIO2+4T3GQSPPZb/ebUlSZIkqQcyoLbR9ttF/sRhVG0YUeimSJIkSd3CpEmTeOyxxxrtu+666zjvvPNavKaiooL6ZSqPO+441q1bt9U5l19+Oddcc02r33v+/PksX768YfuHP/whv/vd73JoffMqKys54YQT2n2ftrr88ssZPHgwY8aMYfjw4dx33315ue9vf/tbxo8fz8iRIxk/fjy///3v83JfA2obVFXBirU78woHMfmknZ0jSZIkScqD008/nXnz5jXaN2/ePE4//fSsrn/kkUfYZZdd2vS9mwbUOXPm8LnPfa5N9yo2s2fPZsmSJTz44IN885vfpKampt33HDhwIA899BBLly7l7rvv5mtf+1oeWmpAbZPKSkjGAATnSJIkSVKPtvqTJFXv1rH6k2S773XyySfz8MMPU11dDcDKlSt55513OPLIIznvvPMoLy/n4IMP5rLLLmv2+n333Zc1a9YAcOWVV3LAAQdwxBFH8Oqrrzacc+utt3LIIYcwevRoTjrpJDZu3Mif//xnFixYwMUXX8yYMWN44403mDFjBr/85S8BWLhwIWPHjmXkyJGcffbZbN68ueH7XXbZZYwbN46RI0fyyiuvZP1Z77vvPkaOHMmIESO49NJLAairq2PGjBmMGDGCkSNHcu211wJwww03MHz4cEaNGsVpp52W4091i2HDhrHddtvx4YcfblXZPf/887nrrruy/lxjx45lr732AuDggw/m008/bfi5tEdZu+/QA1VUQFkp1NZFepdF50iSJElSt/O7VXW892ls9ZzNdZH3P4UIhL/BoH519CkNLZ6/e7/A54aUtnh81113ZcKECTz66KNMnTqVefPmceqppxJC4Morr2TXXXelrq6OyZMn8+KLLzJq1Khm77N48WLmzZvHkiVLqK2tZdy4cYwfPx6AL3/5y5xzzjkA/OAHP+D222/nggsuYMqUKZxwwgmcfPLJje61adMmZsyYwcKFCznggAOYPn06P/vZz5g1axaQqiQ+99xz3HjjjVxzzTXcdtttrf7MAN555x0uvfRSFi9eTP/+/fnCF77A/Pnz2XvvvVm9ejUvvfQSQEN35auvvpo333yTPn36NNuFOVvPPfccw4YNY7fddmtULW5OLp/rV7/6FePGjaNPnz5tbls9K6htkEjAN075CAg8cugcEtjHV5IkST3P5rpUOIXU6+a69t8zs5tvZvfe+++/n3HjxjF27FiWLVvWasB68sknmTZtGttttx077bQTU6ZMaTj20ksvceSRRzJy5Ejuvfdeli1b1mp7Xn31Vfbbbz8OOOAAAM466yyeeOKJhuNf/vKXARg/fjwrV67M6jM+++yzVFRUMGjQIMrKyjjzzDN54oknGDp0KCtWrOCCCy7g17/+NTvttBMAo0aN4swzz+S//uu/KCvLvcZ47bXXcvDBBzNx4kS+//3vZ3VNtp9r2bJlXHrppdx88805t6s5VlDbaPzuq4CdGfrEXTD5J7BwobP5SpIkqdtordJZb/UnSe57rY66CKUBpuxbyuDt21cDmzp1KrNnz+a5555j48aNjB8/njfffJNrrrmGZ599lv79+zNjxgw2bdrUpvvPmDGD+fPnM3r0aO666y4q2zler75qWFpaSm1tbbvu1b9/f1544QUee+wxbrrpJu6//37uuOMOHn74YZ544gkeeughrrzySpYuXdooqH7961/n+eefZ6+99uKRRx7Z6r6zZ8/m29/+NgsWLOAb3/gGb7zxBmVlZSSTW7plN/15ZvO5Vq1axbRp07jnnnvYf//92/XZ61lBbaPd1qT+xeZ9BuJAVEmSJPVEg7cv4fRhpRy1Z+q1veEUYIcddmDSpEmcffbZDdXTjz76iO23356dd96Z9957j0cffbTVexx11FHMnz+fTz/9lA0bNvDQQw81HNuwYQN77rknNTU13HvvvQ37d9xxRzZs2LDVvQ488EBWrlzJ66+/DsDPf/5zjj766HZ9xgkTJvD444+zZs0a6urquO+++zj66KNZs2YNyWSSk046iX//93/nueeeI5lM8vbbbzNp0iTmzp3L+vXr+fjjjxvd784772TJkiXNhtNMU6ZMoby8nLvvvpt99tmH5cuXs3nzZtatW8fChQtz+gzr1q3j+OOP5+qrr+bwww/P+WfQEiuobTToqM/CvfB3dofevXEgqiRJknqiwduXMHj7/N7z9NNPZ9q0aQ1dfUePHs3YsWP57Gc/y957773NQDRu3Di+8pWvMHr0aHbbbTcOOeSQhmNXXHEFEydOZNCgQUycOLEhlJ522mmcc8453HDDDQ2TIwH07duXO++8k1NOOYXa2loOOeQQzj333Jw+z8KFCxkyZEjD9i9+8QuuvvpqJk2aRIyR448/nqlTp/LCCy/w9a9/vaGyedVVV1FXV8dXv/pV1q9fT4yRCy+8sM0zFUNq+ZwzzjiDc845h1NPPZURI0aw3377MXbs2Jzu85//+Z+8/vrrzJkzhzlz5gDwm9/8ht12263NbQMIMbY+8LmzlZeXx/p1jIrZ66/DsGFw8k6P8a2f7EVi5shCN0mSJElql5dffpmDDjqo0M1QN9LcMxVCWBxjLG/ufLv4tlH9OOFfffR5Js8a6VqokiRJktROBtQ2euYZgEikxCGokiRJkpQHBtQ2mjQJAhBIOgRVkiRJkvLAgNpGiQQMH/h3hrKChb+pc4UZSZIkdQvFNkeNuq62PEsG1HY4YJf36MsmEht+U+imSJIkSe3Wt29f1q5da0hVu8UYWbt2LX379s3pOpeZaauqKvZY8SKPczJ8+RD4/e+xjCpJkqSubMiQIaxatYr333+/0E1RN9C3b99Gy+tkw4DaVpWV1CQH8gEDeHzTRI6urDSgSpIkqUvr1asX++23X6GboR7MgNpGVQNO4G4OBOBYHuX3A17HeCpJkiRJbecY1DaqXDuSutALgJrQh8q1IwvcIkmSJEnq2gyobVRRAb16p96XliRdZkaSJEmS2smA2kaJBPz3fwcAZo153OGnkiRJktROBtR2OO641Ot21esK2g5JkiRJ6g6yCqghhGNDCK+GEF4PIXynhXNODSEsDyEsCyH8fxn760IIS9JfC/LV8GLQqxcMLP2Ad9/aDFVVhW6OJEmSJHVp2wyoIYRS4KfAPwLDgdNDCMObnDMM+C5weIzxYGBWxuFPY4xj0l9T8tbyYlBVxU51H/L4R6OpqviuIVWSJEmS2iGbCuoE4PUY44oYYzUwD5ja5JxzgJ/GGD8EiDH+Pb/NLE5V97zGSvblZYYzufoRqu55rdBNkiRJkqQuK5uAOhh4O2N7VXpfpgOAA0IIfwohPBVCODbjWN8QwqL0/hPb19ziUsnRJAlAoJpeVHJ0oZskSZIkSV1WviZJKgOGARXA6cCtIYRd0sf2iTGWA2cA14UQ9m96cQhhZjrELnr//ffz1KSOVzF9H8pCBCK9e5dQMX2fQjdJkiRJkrqsbALqamDvjO0h6X2ZVgELYow1McY3gb+QCqzEGFenX1cAlcDYpt8gxnhLjLE8xlg+aNCgnD9EoSQSMPv4vwCBef93lUvNSJIkSVI7ZBNQnwWGhRD2CyH0Bk4Dms7GO59U9ZQQwkBSXX5XhBD6hxD6ZOw/HFien6YXh6MOqwVgj5IeMexWkiRJkjrMNgNqjLEWOB94DHgZuD/GuCyEMCeEUD8r72PA2hDCcuAPwMUxxrXAQcCiEMIL6f1Xxxi7VUAd8tkdAFj12qcFbokkSZIkdW0hxljoNjRSXl4eFy1aVOhmZG3N6+sYNGwXTtjtab53xXYkZo4sdJMkSZIkqWiFEBan5ynaSr4mSeqx/rLwr0Dk4b8fwuRv7k/VLUsL3SRJkiRJ6pIMqO30+P98AECkJLXUzK/WFrhFkiRJktQ1GVDbqeKkAZSQBJL0poaKkwYUukmSJEmS1CUZUNspMXMkn9v5WXYJH7Hw5jccgypJkiRJbWRAzYNx+3zAJ3E7Jv6T4VSSJEmS2sqAmgfVfXekht48+nCy0E2RJEmSpC7LgNpOVVXwn4sSAJx0UqSqqsANkiRJkqQuyoDaTpX3vEVtunBaU5PaliRJkiTlzoDaThU8Tm9qACiljgoeL3CLJEmSJKlrMqC2U2L6MH7X6x8poZbTwv0kpg8rdJMkSZIkqUsyoLZXIsHhj13GZ3ib+A//AIlEoVskSZIkSV2SATUfJk1ip5KP+dN7+ztJkiRJkiS1kQE1D6qqYFlyOG9+NJDJkzGkSpIkSVIbGFDzoLISkgQgUL05UllZ4AZJkiRJUhdkQM2DigFLKaMWgF7JTVQMWFrgFkmSJElS12NAzYPE2v/lJ1wMwP8NF5NY+78FbpEkSZIkdT0G1HyoqOD4st8A8PtwDFUDTihwgyRJkiSp6zGg5kMiwTszvgtE/ic5jcmzRjpRkiRJkiTlyICaJ38qOxqASKC6GidKkiRJkqQcGVDzpOLzvSkhCUR6l9VRUVHoFkmSJElS12JAzZPEwNf4Ir9mJz5iYZxMAvv4SpIkSVIuDKj58qc/sRfv8BE7Ul2DfXwlSZIkKUdlhW5Ad1E14AR+zgFACcfGR/n9gNdJFLpRkiRJktSFWEHNk8q1I6lN5/3q0JfKtSML3CJJkiRJ6loMqHlSUQG9S5MAlJbhJEmSJEmSlCMDap4kEvC7E/+TUmo59ci/kbB/ryRJkiTlxICaL1VVHP7Qd9iTd3jhDx9QdcvSQrdIkiRJkroUA2q+VFZSVVPOOwzmpXgwk8//LFWuNCNJkiRJWTOg5ktFBZWlxxAJQKC6rsyVZiRJkiQpBwbUfEkkqPjPUyijFoBevYMTJUmSJElSDgyoeZT45ih+tOs1AFx/PU6UJEmSJEk5MKDm2dQ9ngHgN/etdQyqJEmSJOXAgJpPVVW8+/KHQOR/KvszeVKdIVWSJEmSsmRAzafKSv4YDwcgUkJ1NU6UJEmSJElZMqDmU0UFFaVPUkISiPTujRMlSZIkSVKWDKj5lEiQ+MmX+QrzKC1J8tuFpU6UJEmSJElZMqDm27HHMolK6pKlPPiz1Y5BlSRJkqQsGVDz7Z13qKEXAP/33j2cKEmSJEmSsmRAzbdnnmEVQwBIUupESZIkSZKUJQNqvlVUcAL/C0QCSSdKkiRJkqQsGVDzLZHgsMnb8ZnwNv13quO6G5woSZIkSZKyYUDtAFV7ncTquBcffFTGrFk4BlWSJEmSsmBA7QCVn5STJACB6s3RMaiSJEmSlAUDageo2PctelELQFlyMxUDlha4RZIkSZJU/AyoHSBR9iw/56up91TB888XuEWSJEmSVPwMqB3hS19iL94BIo9zNJPvPNNxqJIkSZK0DQbUjnDEETy58xQAIiVU15Y6DlWSJEmStsGA2kEqBr9GKXVAdC1USZIkScqCAbUjVFWR+MvdnMtNQOArk94rdIskSZIkqegZUDtCZSXU1TGUNwC459FBTJ7seqiSJEmS1BoDakeoqIBevXiP3QFIxhKqq3EcqiRJkiS1woDaERIJuP12pvIgEAkBx6FKkiRJ0jYYUDvKtGkcxlMM7fs3dtmhhuuuS+VWSZIkSVLzDKgd5cUXqeJQ3tq0Gx9uKGPWhXWOQZUkSZKkVhhQO0plJZVUkCQAgerq4BhUSZIkSWqFAbWjVFRQUfIkvalJbQcYMKCwTZIkSZKkYmZA7SiJBIn/M46f8C9AJJkMzJrlUjOSJEmS1BIDakfaZx8+ZicAIoHqzdFuvpIkSZLUAgNqR/rb36igklLqgEjv0lqXmpEkSZKkFhhQO9KJJ5LgKc7lJiBw6uc/KHSLJEmSJKloGVA70hFHwJ57cuD2qwH4+a93Z/Jkx6FKkiRJUnMMqB2pqgr+/nf+/kk/AJJJqK7GcaiSJEmS1AwDakeqrIRkkuN4FEgCkdJSHIcqSZIkSc3IKqCGEI4NIbwaQng9hPCdFs45NYSwPISwLITw/2XsPyuE8Fr666x8NbxLqKiAXr0AKCECEEIB2yNJkiRJRWybATWEUAr8FPhHYDhweghheJNzhgHfBQ6PMR4MzErv3xW4DJgITAAuCyH0z+cHKGqJBNx4I5VUECkBArW1dvGVJEmSpOZkU0GdALweY1wRY6wG5gFTm5xzDvDTGOOHADHGv6f3fxH4bYzxg/Sx3wLH5qfpXcTJJ1NBJb1DDQBlZXbxlSRJkqTmZBNQBwNvZ2yvSu/LdABwQAjhTyGEp0IIx+Zwbfe2fDkJnmJBPB6AUUM3FLhBkiRJklSc8jVJUhkwDKgATgduDSHsku3FIYSZIYRFIYRF77//fp6aVCTS/Xl35GMCSZ59eQeXmpEkSZKkZmQTUFcDe2dsD0nvy7QKWBBjrIkxvgn8hVRgzeZaYoy3xBjLY4zlgwYNyqX9xa+iAsrK0uNQAYJLzUiSJElSM7IJqM8Cw0II+4UQegOnAQuanDOfVPWUEMJAUl1+VwCPAV8IIfRPT470hfS+niORgIsvpoJKeoUkkJrJd8CAArdLkiRJkorMNgNqjLEWOJ9UsHwZuD/GuCyEMCeEMCV92mPA2hDCcuAPwMUxxrUxxg+AK0iF3GeBOel9PcvQoSR4ikviVQDU1UVmzbKbryRJkiRlKsvmpBjjI8AjTfb9MON9BL6V/mp67R3AHe1rZhe3ahUA/dgERGLc0s03kShoyyRJkiSpaORrkiS15otfhBA4hj8QSAKR0lKXm5EkSZKkTAbUzpBIwIgR0K8fJSUBCIRQ6EZJkiRJUnExoHaGqip4+WUqP51ATKbm8q2pcSZfSZIkScpkQO0MlZWQTFJBJb2pbtjtTL6SJEmStIUBtTNUVECvXiR4iuvDLCCSTOJMvpIkSZKUwYDaGRIJ+H//D4C1cVcCqW6+mzbBPfcUsmGSJEmSVDwMqJ1l/XoAKqiklFoAYoQ777SKKkmSJElgQO08FRVQWkqCpzit9BcNu2trnSxJkiRJksCA2nkSCTj3XAD++YtvQrqbr+uhSpIkSVKKAbUzDRuWen30UUpIAtH1UCVJkiQpzYDamd5/H4DKeFS6fhrs4itJkiRJaQbUznT88RACFTxOn/R6qDG6HqokSZIkgQG1cyUSMGIEie1f5PoznwFwPVRJkiRJSjOgdqaqKnj5ZfjkE9b+90LXQ5UkSZKkDAbUzlRZmSqZAhXJ31NaUge4HqokSZIkgQG1c1VUQO/eACSo4muHvtZwyMmSJEmSJPV0BtTOlEjA9den3ieTnLPovIZuvq6HKkmSJKmnM6B2trVrt7yvraUkpBeccT1USZIkST2cAbWzVVRAWRkAlSXHEEkl0+pqJ0qSJEmS1LMZUDtbIgGXXw5AxeE1lJWlJk1yoiRJkiRJPZ0BtRAOOgiAxBNzOTt5O6THoTpRkiRJkqSezIBaCK+8knqNkenxHnqVpKqoIcCAAQVslyRJkiQVkAG1ECZNapgVKVH2LHNmvg1AXR3MmmU3X0mSJEk9kwG1UErSP/oQGiZKihE2b7abryRJkqSeyYBaCJWVqTQKUFPDgHeXNRxKJu3mK0mSJKlnMqAWQkUF9O7dsLmWgY3WQX3++c5vkiRJkiQVmgG1EBIJuP761PtkkopHLqFXWV3DYZebkSRJktQTGVALZe3ahreJuj9y9tgXGrarq+GeewrRKEmSJEkqHANqoVRUQK9eqfchML3ir5SVpTZjtIoqSZIkqecxoBZKIgGXXJJ6X1dH4j/O4GtffK/hcG2ts/lKkiRJ6lkMqIXUr1/qNUaoruacvR9rmCyptDRVZJUkSZKknsKAWkjHHEOjRDp2LKWlqc36VWgkSZIkqacwoBZaSfp/ghCofH6nzOVRnShJkiRJUo9iQC2kykoyE2kFjzdUUMGJkiRJkiT1LAbUQqqogD59GjYTYzdx9tlbDrvcjCRJkqSexIBaSIkEXHdd6n0yCbNmMX3sUnr3Tu1yuRlJkiRJPYkBtdDWrt0yUVJ1NYm1/9uoilpT43IzkiRJknqGskI3oMerqIBevVL9eQEGDGDsgC2Hk0kYMKDZKyVJkiSpW7GCWmiJBFxxRep9upvv2uffapjcF+D55wvTNEmSJEnqTAbUYlBXl3qNETZvpoLHKcuobd96K9xyS2GaJkmSJEmdxYBaDAY07tPbdDbfujo4/3wnS5IkSZLUvRlQi0HmREklJbB2LdOn06iKWlvrZEmSJEmSujcDajFosh4qAwaQSMC3vrVlV4xOliRJkiSpezOgFoNEAq6/PvU+PVESVVXsssuWwio4WZIkSZKk7s2AWiyarIdKZWXDCjT17rzTcaiSJEmSui8DarFomkbT3XwzJ0uqroZ77un0lkmSJElSpzCgFotEAubMSb3P6OY7fTr07p3aHaNVVEmSJEndlwG1mCSTqdf0eqhUVm5VRa2pcTZfSZIkSd2TAbWYNFkPtX577NjGu9et69xmSZIkSVJnMKAWk2bWQ226G+Daa+3mK0mSJKn7MaAWk4oK6Nt3y3a6glpRAaWlW3bX1jpZkiRJkqTux4BaTBIJuO66VLk0Y6KkRAJ++tMtITVGuPVWuOWWQjZWkiRJkvLLgFps0t16Adi0qaFUOnMmnHPOlkN1dXD++Xb1lSRJktR9GFCLTUUFlJWl3jdZV2b69K27+jqjryRJkqTuwoBabJquK5ORQhMJ+Jd/2XIoxsYT/0qSJElSV2ZALUZnnZWaxRdSJdOKioZDu+yyZUbfEOD55zu9dZIkSZLUIQyoxaqk+f9pKiqgV6/UeydLkiRJktSdGFCLUWVlKn0CVFc3WlOmaQ9gJ0uSJEmS1F0YUItR04VPMyZKgtRkSfXzKIGTJUmSJEnqHgyoxahpmbSZKuq3vrXlcIywbl3nNU+SJEmSOoIBtVhNn954sGmTKuouuzQ+/dpr7eYrSZIkqWszoBarplXUmppG/Xgzl0uFVDffjCKrJEmSJHU5BtRiNm7clvfJZKNFTxMJ+OlPt0z2GyPcfrtVVEmSJEldV1YBNYRwbAjh1RDC6yGE7zRzfEYI4f0QwpL01z9lHKvL2L8gn43v9tau3bLoaUlJajvDzJnwpS9t2a6pgR//uBPbJ0mSJEl5VLatE0IIpcBPgc8Dq4BnQwgLYozLm5z63zHG85u5xacxxjHtbmlPVFEBffvCp5+mtjMqqPX23LPx9kMPpaqoiUTHN0+SJEmS8imbCuoE4PUY44oYYzUwD5jasc0SkEqZ112XqqImkzBr1lZ9eKdPb7wiTTLpWFRJkiRJXVM2AXUw8HbG9qr0vqZOCiG8GEL4ZQhh74z9fUMIi0IIT4UQTmzuG4QQZqbPWfT+++9n3fgeIbNb76ZNW6XPRAJuvNGxqJIkSZK6vnxNkvQQsG+McRTwW+DujGP7xBjLgTOA60II+ze9OMZ4S4yxPMZYPmjQoDw1qZuoqGh1uRlwLKokSZKk7iGbgLoayKyIDknvaxBjXBtj3JzevA0Yn3Fsdfp1BVAJjG1He3uebSw3U6+lsaiSJEmS1FVkE1CfBYaFEPYLIfQGTgMazcYbQsiMR1OAl9P7+4cQ+qTfDwQOB5pOrqRtGZuR6ZssN1PPsaiSJEmSurptBtQYYy1wPvAYqeB5f4xxWQhhTghhSvq0C0MIy0IILwAXAjPS+w8CFqX3/wG4upnZf7Uta9duGWQK8PzzW53iWFRJkiRJXV2IMRa6DY2Ul5fHRYsWFboZxaWqKjUWtbo6td2nD/zhD82uJXPiifDgg423H3igMxopSZIkSdsWQlicnqdoK/maJEkdqek41OrqFvvvOhZVkiRJUldlQO0qpk+H3r1T71uYzbf+NMeiSpIkSeqKDKhdRZZV1PqxqPUh1bGokiRJkroKA2pXklkebaWK6rqokiRJkroiA2pXkkjAySdv2W5hTVSAPfZovP3gg3DLLR3XNEmSJElqLwNqV3PMMVvet7AmKmw9FjVG+Od/tquvJEmSpOJlQO1q1q6FEFLvQ2h2TVTYMha1/lSAujq7+kqSJEkqXgbUrqaiAnr1Sr1vZRwqpMaiTp3aeJ/LzkiSJEkqVgbUriaHNVEBLrnEZWckSZIkdQ0G1K4oy9l8wWVnJEmSJHUdBtSuKJFIhdR6rczmCy47I0mSJKlrMKB2VYceuuV9K7P51nPZGUmSJEnFzoDaVWU5m289l52RJEmSVOwMqF1VDrP5gsvOSJIkSSp+BtSuKsfZfKH5ZWfs6itJkiSpWBhQu7Lp0xtXUbOYnrfpsjN29ZUkSZJULAyoXVkiAccdt2W7pmabVVS7+kqSJEkqVgbUrm7PPRtvv/vuNi+xq68kSZKkYmRA7eqmT4eysi3bjz6aVX/d5rr6nnsuXHppB7RRkiRJkrJgQO3qEgn4p3/asp3FZEn1l914I5RkPAExprr6GlIlSZIkFYIBtTvIrKJmseRMvZkz4Wc/azweFeAnP7G7ryRJkqTOZ0DtDpouOVNTA5WVWV06cyZcfHHjfc7sK0mSJKkQDKjdxfjxW94nk7BuXdaXzp2bGpOayZl9JUmSJHU2A2p3sXZt4766116bUwl07lw48cTG+5zZV5IkSVJnMqB2FxUVjaflra3NarKkTC3N7GtIlSRJktQZDKjdRSIBP/3plml5c5gsKfMWN97YuBBrSJUkSZLUWQyo3cnMmY2XnMlhsqTMW0yd2nifkyZJkiRJ6gwG1O6mHZMl1bvkEujVq/G+urpU9jWkSpIkSeooBtTupp2TJUGqq+/jj8Pw4Y33L18ORx9tSJUkSZLUMQyo3U0eJkuCVEi97bbGt4JUr2GXn5EkSZLUEQyo3U1zkyXdfnubyp7NTZoEMH8+XHpp+5sqSZIkSZkMqN3RzJnwpS9t2a6paVMVtf5WN920dUj98Y8NqZIkSZLyy4DaXe25Z+Ptd99t860MqZIkSZI6gwG1u5o+vfFUvI8+2q7ZjWbOhIsv3nq/IVWSJElSvhhQu6tEAr7xjS3b1dVt7uZbb+7c1BI0TRlSJUmSJOWDAbU7mz4devdOvW/HZEmZWgupLkEjSZIkqT0MqN1ZIgHHHbdlux2TJWVqKaQ+8QQccQTccku7v4UkSZKkHsiA2t3tsUfj7XZMlpSppZCaTMI3v2mXX0mSJEm5M6B2d00nS3roobyVOFsKqeC4VEmSJEm5M6B2d00nS6qrg/PPz9tg0blz4eaboaSZJ8mQKkmSJCkXBtSeYPp0KCvbsl1bC5WVebv9zJnwxz/CUUdtfczJkyRJkiRly4DaEyQS8K1vbdmOEdaty/u3ePzxlidPOvxwq6mSJEmSWmdA7Sl22QVC2LJ9zTUdMt1uS+NSY7SaKkmSJKl1BtSeoqICSku3bCeTeR2Lmqk+pGbm4Xr11dRp0wyqkiRJkhozoPYUiQT89KeNZzPK81jUTHPnwp/+1Py41Bhh/nzXTJUkSZLUmAG1J5k5E7797S3bHTAWNVNr41LBNVMlSZIkNWZA7WmajkW99toO72vb2lI04NhUSZIkSSkG1J6m6VjU2lq4554O/7b1S9GceKJjUyVJkiQ1z4Da09SPRa0PqTHC7bd3SipMJOCBBxybKkmSJKl5BtSeaOZM+NKXtmzX1KT62XaSbMem2u1XkiRJ6lkMqD3VHns03n7ooU5Pg9sam/rEE3DYYQZVSZIkqacwoPZU06dvvS5qJ4xFbWpbY1PBoCpJkiT1FAbUniqRgBtvbDwW9dZbCzL4c1tjU+sZVCVJkqTmLVlTx92v1vBff6nh12/XsvqTZKGb1CYhxljoNjRSXl4eFy1aVOhm9BznnQc33bRlu7QUnnwylRoL5JZb4Ec/grfeav284cPhootSVVhJkiSpUFZ/kuSpd+v4YDP0K0vt+7QWSgIkY/tf+5UBETam71kXIQBJUq8ba2FzkzxaGuCMYaUM3r74apIhhMUxxvJmjxlQe7iqKjjySKir27LvxBNTJc0Cyzao7rEHHHpoatKlAuZqSZIk5WDJmjpeWJukNplFOKMDAt+27kkqCNYHwvr9mcGwLkJdEj6pa/4zFtrRe5aQ2KN02yd2MgOqWjdtWmp9l3pFUEXNlG1QhVQX4auvLpqmS5KkHi7bENYZoWyralxdKoQlM0JYaZPXpqGspJnXugh9y1IjxjbXbfv7h5D6XE0rfsovK6h5YkAtgKZV1BBS67z87GeFbVcTt9wC110HL7+87XOHDYP+/eEb37ALsCRJ3VlBqnA0rqzVh7NNdekgZwhTAQ3qC4N3CIzctaQowykYUJWNW25JjUdNpn+L9uqVWqy0CEuRVVXwne+kJk3Khl2AJUnKn9WfJFm6NskntZFPazuwwkfq3vWBL9txd1IhbVcKu/ZNve/sLsm79g0cunvxhtJMBlRl58QT4cEHG28XwVjUllRVwY9/DE89Be++m901VlYlSV1RW7uJtql6yNbj7urS+zfXFe9YO3Vdu/ROdUctujGoObyWlcDoASWMGVh84z2LkQFV2Wk6o28Iqe0ukORyGadab489Ul+9extYJUkp9dXBNZtiq3+4dsQfzH1LIabvGTLC4sZa2GSVsMvbVgjr9DGoeb53W+7ZlSp+yi8DqrLT3Iy+RTZh0rbccgvcfjt8+CG89lpu1+6xBxxwQOr9pk2GVknKRnsrex36B3NG4GuuGpi5HYCaZGrSGHVNhajCZXNvQ5i0NQOqsnfLLXDuuamR/vWKvKtvS9rSBbip+irr5s3Qp4/VVkkdI3P9vGKokAS2bDeaCKa08T0d/6dBffMb9Nry/BoApa6n3QE1hHAscD1QCtwWY7y6yfEZwE+A1eld/xljvC197CzgB+n9/x5jvLu172VALQJNl53pQl19W9KeympzmgbXzZvhwAOdiElqq2y7VRZrl7imga5+eYbMbpr1k7ok0/vrIvQpSVXt1tcU5ueurifXbqId8f8b/cpgYL/iniFUUnFrV0ANIZQCfwE+D6wCngVOjzEuzzhnBlAeYzy/ybW7AouAclK9bBYD42OMH7b0/QyoRaC5rr5FPKtvruorq6++CrW1+QmsAPtPTHLI1CTjDovsMqj1Pwr81161R0tdKotlTFGLr0AdW7pW9itL/Yfh42rYUFuYn6XUmp16QZ/STuySbDdRST1EawG1LIvrJwCvxxhXpG82D5gKLG/1qpQvAr+NMX6Qvva3wLHAfdk0XAWSSMCNNzZedqa2Fioru0VATSQa91jODKyDBsFHH8GSJbnd8zOjksy4oY6yXqk/wNduIlUqAdi89flrN0deW1/HjmV1lJWk/jU80vY/ZuqiM8dlI9excgULfDQOcpmLpX9a28oYuWaetXbriHumfVjdcfdW52trZa/g//9mdVCSiko2AXUw8HbG9ipgYjPnnRRCOIpUtXV2jPHtFq4d3Ma2qjPNnAlvvJFKbpAak7puXUGb1FGaBlZoHFrru/C2Vm3db3ykJDMbhubPa6rdVaOM8PC3jUkq30k2TApSQuPQW5rxR1hrYbjoZw1k6ypc/T1DSD2qgVR3ysxJUNo0Vq6LBT51fduVwva9iuj/37K4p5U9SVI+ZRNQs/EQcF+McXMI4ZvA3cAx2V4cQpgJzAT4zGc+k6cmqd122WXLX/wA11wD++/fpceiZqu50ArNB9c+feDT1YG6Ggi9U+eFhv/TuTbVpb7apSMDVAfc2ypc99Nat8pChLLOCHz2gpAkKSWbgLoa2DtjewhbJkMCIMa4NmPzNuDHGddWNLm2suk3iDHeAtwCqTGoWbRJnaGiIrXMTG26zJdMwj//M4wc2S26+rZFS8EVSvj1U/D820l23ivSa/uW/6j9pMZlDJQfTbtUFksXybbc226VkiQJspskqYxUt93JpALns8AZMcZlGefsGWP8W/r9NODSGOOh6UmSFgPj0qc+R2qSpA9a+n5OklRkutGyM8Ukn+sGbq6D9zcV+hN1LdmOlSvWwGeXSkmS1JW1a5KkGGNtCOF84DFSy8zcEWNcFkKYAyyKMS4ALgwhTAFqgQ+AGelrPwghXEEq1ALMaS2cqgjNnAmPPtp42ZkHH0wF1x7Q1bejjBlYmteufPlcQ7GrdpF0rTxJkqSuL6t1UDuTFdQi1NyyM6Wl8OSTPbarryRJkqS2aa2CahlB21a/7EzImPWnrm7LDL+SJEmSlAcGVGVn5kyYOrXxvvnz4dJLC9IcSZIkSd2PAVXZu+SSVNfeTD/+sSFVkiRJUl4YUJW95rr6AvzkJ6lJkyRJkiSpHQyoys3MmXDxxY33xZhaH7WqqjBtkiRJktQtGFCVu7lzU919MzlpkiRJkqR2MqCqbebOhRNPbLyvfn1USZIkSWoDA6rarumkSXb1lSRJktQOBlS1neujSpIkScojA6rax/VRJUmSJOWJAVXt5/qokiRJkvLAgKr2c31USZIkSXlgQFV+uD6qJEmSpHYyoCp/XB9VkiRJUjsYUJVfza2POn8+TJtmJVWSJElSqwyoyr/mJk2aPx+OPtqQKkmSJKlFBlTlX/2kSSVNHq+aGrv7SpIkSWqRAVUdY+ZM+NnPtp7Z1zVSJUmSJLXAgKqOM3Mm3HTT1iHVNVIlSZIkNcOAqo5lSJUkSZKUJQOqOl5za6SCIVWSJElSIwZUdY7m1kgF+MlP4JZbOr89kiRJkoqOAVWdp7mQGiOce64hVZIkSZIBVZ3MkCpJkiSpBQZUdb65c+HEExvvM6RKkiRJPZ4BVYVxySXQq1fjfYZUSZIkqUczoKowEgl4/HEYPrzxfkOqJEmS1GMZUFU4iQTcdlvzldRvftMlaCRJkqQexoCqwmqpkgqukypJkiT1MAZUFV5LlVQwpEqSJEk9iAFVxaG+knrUUVsf+/GP4eijoaqq89slSZIkqdMYUFU86kNq03VSAZ54wpAqSZIkdXMGVBWfuXObD6k1NfBP/2RIlSRJkropA6qKU0shdflyOOIIl6GRJEmSuiEDqorX3Llw880QQuP9yWRqGZpp06ymSpIkSd2IAVXFbeZMuOmmrUMqwPz5VlMlSZKkbsSAquJXH1JLmnlc66upLkUjSZIkdXkGVHUNM2fCH/8IJ57YfDXVpWgkSZKkLs+Aqq4jkYAHHmi5mvrEE3b5lSRJkrowA6q6nvpq6lFHbX3MLr+SJElSl2VAVdeUSMDjjze/FA3Y5VeSJEnqggyo6trql6Kxy68kSZLU5RlQ1fVl0+XXaqokSZJU9Ayo6h621eX3iSfg8MMdmypJkiQVMQOqupfWuvzG6NhUSZIkqYgZUNX9tNblF7ZUU6dNM6hKkiRJRcSAqu6pvsvvzTfDPvtsfTxGmD/foCpJkiQVEQOqureZM2HlypbHptYHVWf7lSRJkgrOgKqeobWxqeBsv5IkSVIRMKCq56gfm3riiRBC8+c88QQcdhgcfLAVVUmSJKmTGVDVsyQS8MAD8Kc/tR5Uly9PVVT328+gKkmSJHUSA6p6psyg2tJsv5Aav2pQlSRJkjqFAVU9W+Zsvwcd1PJ59UF1zz2d9VeSJEnqIAZUCVLjU5cvhz//ufWK6rvvpmb9PewwJ1SSJEmS8syAKmWqr6huK6jClgmVxo6F884zrEqSJEntZECVmpNLUF2yBG66Cb58Nnz1cljwRGe0UJIkSep2DKhSazKD6oknwh57NH/e7p+FL10JO46Hhz+Ebz8CNy+CFR92anMlSZKkrqys0A2QuoT6WX8hNZvvj34Eb7215fheI6GkF4QSKAmwMQkvvJf6GrwjDO0PE4ekXiVJkiQ1y4Aq5WrmzNTXLbfAddfBK6/AO0shJiGGrddWXb0h9fXkX2HgdrBDLzjsM3DEZwrSfEmSJKlYhRhjodvQSHl5eVy0aFGhmyFlr6oK7rkH1u8MOx+eqqJmY8fesPv2sOeOVlclSZLUY4QQFscYy5s7ZgVVaq9EIvUFqTGnv3kD3vwQNlS3ft2G6tTX6x+mqqu79oO9d4LP729YlSRJUo9kQJXyaWh/ODf9j0F//Cv86a/wSQ2s2bjtaz/4NPX1wnt2BZYkSVKPZECVOsoRGeEy17C6ZiOsAVYuhYdehZ36QK8SA6skSZK6tawCagjhWOB6oBS4LcZ4dQvnnQT8EjgkxrgohLAv8DLwavqUp2KM57a71VJXkxlW67sBr1oPH2za9rX1XYGhcWCtS8LuO9glWJIkSd3GNgNqCKEU+CnweWAV8GwIYUGMcXmT83YELgKebnKLN2KMY/LTXKkbyOwGvOJDeGoVvLsB3vtk2+NWoXFgffeTVJfgXftBvzJDqyRJkrq0bCqoE4DXY4wrAEII84CpwPIm510BzAUuzmsLpe5saP/GQTLXrsD1Pvh0y/v60DpwOygLBlZJkiR1GdkE1MHA2xnbq4CJmSeEEMYBe8cYHw4hNA2o+4UQngc+An4QY3yyPQ2WurXmugL//WOojbkFVthyftPAWlrieFZJkiQVpXZPkhRCKAH+HzCjmcN/Az4TY1wbQhgPzA8hHBxj/KjJPWYCMwE+8xn/YJaAxl2BoXFgLS2BT2uyG8Nar2nAbTqedYferskqSZKkggoxxtZPCCEBXB5j/GJ6+7sAMcar0ts7A28AH6cv2QP4AJgSY1zU5F6VwLeb7s9UXl4eFy1q8bCkTE1D60ebsxvHui2Dd0yFVqutkiRJyrMQwuIYY3lzx7KpoD4LDAsh7AesBk4Dzqg/GGNcDwzM+GaVpENoCGEQ8EGMsS6EMBQYBqxo8yeR1FjTKitsGcdam2x7YF29ofG21VZJkiR1gm0G1BhjbQjhfOAxUsvM3BFjXBZCmAMsijEuaOXyo4A5IYQaIAmcG2P8IB8Nl9SCI5pUOzMDa12ybeNZofHswXwCr38IT/618QzCBldJkiS1wza7+HY2u/hKnaC941mzkRlc7SosSZKktPZ28ZXU3TTXNbh+TdYNm+GTavi4uu3VVmi89E29lUvhN69DWUkqtBpeJUmSlMGAKiml6Zqs9fJdbV3TTHCFrce5GlwlSZJ6HAOqpNa1Vm19d0Oq0pqvbsKNxrmmNRdcHe8qSZLULRlQJeWutWpr0+DanomZ6jUXXDMnaspcFsfqqyRJUpdlQJWUPy0FV+i48ApbL4tTr6XqqwFWkiSpKBlQJXWObYXXzHGu+Qqu0EL1Nc3uw5IkSUXFgCqp8Job5wrNB9d8L4vTlu7DdUnYfQf4/P4GWEmSpDwyoEoqXi0FV2h+WZx8V1+h5e7D734CL7wHA/ttvWyOVVhJkqQ2MaBK6ppa6zIMLVdf8x1gW1o2J7MKu2s/6Fe2JbhCKlAbYiVJkhoxoErqnlqrvkLndB+u90FmiP2k8fvmQqxVWEmS1EMZUCX1TG3tPlxaAh9tbnnipbb6oLlKbEaA7d8XtuvlbMSSJKlbM6BKUlPb6j4M8Me/wp/+CrXJrUNjR1RhP9yU+mpO/WzEu20Pga0DtSFWkiR1EQZUSWqLI7YR+Fpa97V+DOoHn+Y3xLa2nA60vias3YklSVKRMKBKUkfIpgrbUojtqCpsqyE2i0mdrMZKkqQOZkCVpELJZibilgJsvmcjztTipE5pK5fCgldh5xaqsa4VK0mS2siAKknFKtsqbP1sxE2rnR0ZYj9OTx7Vmvq1Ygf0S1Vem+tWXH8vw6wkScKAKkld27aW04HW14TtqO7Emda2slZsvfowO7AflDUTZh0rK0lSj2BAlaTuLtsQ29qkTh9Xd1w1NtOalsJsvYyxsrv0ge16Q7KFqqxdjSVJ6nIMqJKk7LoTw7arsR25VmxT6zanvhppZsxsfXV2176prsZlpY6dlSSpSBlQJUnZy6YaW6+1tWIzq53vfdLxYRay78bcEGj7pMJsr9KWq7OGWkmS8sqAKknqGNtaKzbTtsJsZ4yVbeqDLKqz9bY1IZRjaSVJyooBVZJUeNmG2W0tvdO0ytkZXY0ztTghVFMZY2l32w4iqUptspVQa7iVJPUABlRJUteR7VjZTNlUZztz7GxTf8914qmMcLtzH+jXC4jbDuuGW0lSF2BAlSR1b7l0NYaWA21LY1ALEWrrrd+c+mpWc12Sm8yC3K8XxGbCrRNISZIKxIAqSVKmXAMt5Fal7eyxtC1pdhbkbagfa9uWcGv1VpKUBQOqJEntlWuorR9Lu2EzfFLd/Hja7hZut1W9bW2WZEOuJPUYBlRJkjpbW8bS1tvWRFEtBb5iCbeQ/Rq2W8kIuf37wna9tl21hS0/g14lcFgbKuSSpE5jQJUkqSvpjHBbzNXbeh9uSn21qpnQu3IpLHgFduyTWxdlx+FKUqcwoEqS1FO0J9xCKuD+5g34+8ddO9x+XJP6aov6cbh7bJ/qpvxpTe4h167KktQiA6okScrO0P5wbnnbrs11DdtiD7nvZtMluSUtjMfNZhyuYVdSN2dAlSRJHa+91VvIvYtyZuCrjbAm1zVnO0Gj8bhtCb1NxuX26wXJLMbjtvRzc5yupAIzoEqSpK6hUF2Ui2HN22y0Oi43h/Cb7Tjd1kKvY3UltZEBVZIk9Qzt6aJcr37N214lqe2uPtlUS7Iap9tK6K0fq9u/D5SWpn5eySSUlWbfdRmcgVnqgQyokiRJ2cp1zdvmtNRVOdcxqF0h7H6Y63q59bYxA3MuYbe5n69jd6WiZUCVJEnqTPkYj1uvreviNndOsY7TzdSeGZgbhd5mJqpqS+jN/Plu3xt26mPoldrJgCpJktRV5TPsQm7jdFsKvcU+VrepRhNVtVVG+M1n6LXKqx7IgCpJkqSUfIzThS1jdWuTbQ9nUNwzMLcmX6G3YYbmNo7ldYZmdUEGVEmSJOVXPsbqZmrvDMyZofeDT4t/7G5TbR7L28TKpTD/ZejfDwKwqQ7KSiC2o9LrjM3KMwOqJEmSilu+Krv1cl1TN5vX1Rvy176OtLEWNuaxrfUzNg/cDvqWtj/0Wunt8QyokiRJ6lnyPXYX8h96u1rX5ny2tb7Su13v1Fq8O/QCAmyqsdLbAxhQJUmSpPbqiNDb3rG8XTXsQrrSW5t6v/bT9t+vvtK7c59UhTcfodcJrTqEAVWSJEkqRvkcy5s5jjfXNXdbeu1qMzYDrE+P581H6G3QZNminftCSUitVZyP7uM9rNuzAVWSJEnq7vI9jrdefZW3V0lquz2htytWepvKywzOzVi5FB79S2o257KQ6vrcUuW3i1d0DaiSJEmS2qYzZmxub8W3K1Z6m5P1bM7pim7VKph1aJcLqQZUSZIkScWhoyu99eN589XN+dOa4l22qDYJf1lrQJUkSZKkopLvSm+mpjM45yv8trfbc1kJHDAgf5+zkxhQJUmSJKmtOmIG50y5LmHkGFRJkiRJUofo6ABcZEoK3QBJkiRJksCAKkmSJEkqEgZUSZIkSVJRMKBKkiRJkoqCAVWSJEmSVBQMqJIkSZKkomBAlSRJkiQVBQOqJEmSJKkoGFAlSZIkSUXBgCpJkiRJKgoGVEmSJElSUTCgSpIkSZKKggFVkiRJklQUDKiSJEmSpKJgQJUkSZIkFQUDqiRJkiSpKIQYY6Hb0EgI4X3grUK3YxsGAmsK3QgVJZ8NtcbnQy3x2VBrfD7UEp8NtaTYn419YoyDmjtQdAG1KwghLIoxlhe6HSo+Phtqjc+HWuKzodb4fKglPhtqSVd+NuziK0mSJEkqCgZUSZIkSVJRMKC2zS2FboCKls+GWuPzoZb4bKg1Ph9qic+GWtJlnw3HoEqSJEmSioIVVEmSJElSUTCg5iiEcGwI4dUQwushhO8Uuj3qXCGEvUMIfwghLA8hLAshXJTev2sI4bchhNfSr/3T+0MI4Yb08/JiCGFcYT+BOloIoTSE8HwI4X/T2/uFEJ5OPwP/HULond7fJ739evr4vgVtuDpcCGGXEMIvQwivhBBeDiEk/N0hgBDC7PR/U14KIdwXQujr746eK4RwRwjh7yGElzL25fy7IoRwVvr810IIZxXisyi/Wng2fpL+78qLIYQHQgi7ZBz7bvrZeDWE8MWM/UWdZwyoOQghlAI/Bf4RGA6cHkIYXthWqZPVAv8SYxwOHAr8n/Qz8B1gYYxxGLAwvQ2pZ2VY+msm8LPOb7I62UXAyxnbc4FrY4z/AHwIfCO9/xvAh+n916bPU/d2PfDrGONngdGknhN/d/RwIYTBwIVAeYxxBFAKnIa/O3qyu4Bjm+zL6XdFCGFX4DJgIjABuKw+1KpLu4utn43fAiNijKOAvwDfBUj/fXoacHD6mhvT/4he9HnGgJqbCcDrMcYVMcZqYB4wtcBtUieKMf4txvhc+v0GUn9gDib1HNydPu1u4MT0+6nAPTHlKWCXEMKendtqdZYQwhDgeOC29HYAjgF+mT6l6bNR/8z8EpicPl/dUAhhZ+Ao4HaAGGN1jHEd/u5QShnQL4RQBmwH/A1/d/RYMcYngA+a7M71d8UXgd/GGD+IMX5IKsQ0DTbqYpp7NmKMv4kx1qY3nwKGpN9PBebFGDfHGN8EXieVZYo+zxhQczMYeDtje1V6n3qgdLeqscDTwO4xxr+lD70L7J5+7zPTs1wHXAIk09sDgHUZ/+HI/N+/4dlIH1+fPl/d037A+8Cd6S7gt4UQtsffHT1ejHE1cA3wV1LBdD2wGH93qLFcf1f4O6RnOht4NP2+yz4bBlSpDUIIOwC/AmbFGD/KPBZTU2M7PXYPE0I4Afh7jHFxoduiolQGjAN+FmMcC3zCli56gL87eqp0t8uppP4RYy9ge6x0qRX+rlBzQgjfJzUU7d5Ct6W9DKi5WQ3snbE9JL1PPUgIoRepcHpvjPF/0rvfq+9+l379e3q/z0zPcTgwJYSwklR3mWNIjTncJd1tDxr/79/wbKSP7wys7cwGq1OtAlbFGJ9Ob/+SVGD1d4c+B7wZY3w/xlgD/A+p3yf+7lCmXH9X+DukBwkhzABOAM6MW9YQ7bLPhgE1N88Cw9Iz6/UmNfB4QYHbpE6UHudzO/ByjPH/ZRxaANTPkHcW8GDG/unpWfYOBdZndNFRNxJj/G6McUiMcV9Svxt+H2M8E/gDcHL6tKbPRv0zc3L6fP9FvJuKMb4LvB1CODC9azKwHH93KNW199AQwnbp/8bUPxv+7lCmXH9XPAZ8IYTQP12l/0J6n7qZEMKxpIYXTYkxbsw4tAA4LT3z936kJtJ6hi6QZ4K/03ITQjiO1DizUuCOGOOVhW2ROlMI4QjgSWApW8YZfo/UONT7gc8AbwGnxhg/SP+x8Z+kumttBL4eY1zU6Q1XpwohVADfjjGeEEIYSqqiuivwPPDVGOPmEEJf4OekxjF/AJwWY1xRoCarE4QQxpCaQKs3sAL4Oql/KPZ3Rw8XQvg34Cukuuc9D/wTqTFh/u7ogUII9wEVwEDgPVKz8c4nx98VIYSzSf2NAnBljPHOTvwY6gAtPBvfBfqwpSfFUzHGc9Pnf5/UuNRaUsPSHk3vL+o8Y0CVJEmSJBUFu/hKkiRJkoqCAVWSJEmSVBQMqJIkSZKkomBAlSRJkiQVBQOqJEmSJKkoGFAlSZIkSUXBgCpJkiRJKgoGVEmSJElSUfj/Aea4vjA9qn4TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loss indica quão bom o modelo está se ajustando aos dados de treino, enquanto validation loss indica quão bem o modelo se ajusta a novos dados. Pelo gráfico acima é possível notar que para run1, que o modelo se ajusta dados de treino mas não se ajusta a novos dados. Enquanto pra run2 o modelo se ajustou de forma mais eficiente em relação à run1 a dados de treino e dados novos. O número de épocas apropriado para run seria em torno de 300 e para run2 train loss ainda está a cair em 1200 épocas e seria possível aumentar para observar uma curva a tender a uma constante.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 24ms/step - loss: 0.7032 - accuracy: 0.5312 - val_loss: 0.7135 - val_accuracy: 0.5365\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7011 - accuracy: 0.5434 - val_loss: 0.7117 - val_accuracy: 0.5521\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6991 - accuracy: 0.5521 - val_loss: 0.7100 - val_accuracy: 0.5625\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6972 - accuracy: 0.5642 - val_loss: 0.7084 - val_accuracy: 0.5677\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6953 - accuracy: 0.5729 - val_loss: 0.7069 - val_accuracy: 0.5781\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5851 - val_loss: 0.7054 - val_accuracy: 0.5729\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6919 - accuracy: 0.5920 - val_loss: 0.7040 - val_accuracy: 0.5938\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6903 - accuracy: 0.6007 - val_loss: 0.7026 - val_accuracy: 0.5990\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6887 - accuracy: 0.6128 - val_loss: 0.7013 - val_accuracy: 0.6146\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6872 - accuracy: 0.6181 - val_loss: 0.7000 - val_accuracy: 0.6146\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6858 - accuracy: 0.6146 - val_loss: 0.6988 - val_accuracy: 0.6146\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6844 - accuracy: 0.6128 - val_loss: 0.6977 - val_accuracy: 0.6198\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.6831 - accuracy: 0.6163 - val_loss: 0.6966 - val_accuracy: 0.6198\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.6818 - accuracy: 0.6163 - val_loss: 0.6955 - val_accuracy: 0.6302\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6805 - accuracy: 0.6250 - val_loss: 0.6945 - val_accuracy: 0.6354\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6793 - accuracy: 0.6163 - val_loss: 0.6935 - val_accuracy: 0.6354\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.6781 - accuracy: 0.6181 - val_loss: 0.6925 - val_accuracy: 0.6302\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.6769 - accuracy: 0.6198 - val_loss: 0.6915 - val_accuracy: 0.6250\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6758 - accuracy: 0.6250 - val_loss: 0.6906 - val_accuracy: 0.6250\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.6746 - accuracy: 0.6319 - val_loss: 0.6896 - val_accuracy: 0.6198\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6735 - accuracy: 0.6302 - val_loss: 0.6887 - val_accuracy: 0.6302\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.6725 - accuracy: 0.6337 - val_loss: 0.6878 - val_accuracy: 0.6354\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.6715 - accuracy: 0.6389 - val_loss: 0.6870 - val_accuracy: 0.6406\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6705 - accuracy: 0.6424 - val_loss: 0.6861 - val_accuracy: 0.6458\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6695 - accuracy: 0.6441 - val_loss: 0.6853 - val_accuracy: 0.6458\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.6686 - accuracy: 0.6441 - val_loss: 0.6845 - val_accuracy: 0.6458\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6676 - accuracy: 0.6458 - val_loss: 0.6837 - val_accuracy: 0.6458\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.6667 - accuracy: 0.6424 - val_loss: 0.6830 - val_accuracy: 0.6458\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.6658 - accuracy: 0.6441 - val_loss: 0.6822 - val_accuracy: 0.6458\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.6649 - accuracy: 0.6441 - val_loss: 0.6815 - val_accuracy: 0.6458\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6641 - accuracy: 0.6441 - val_loss: 0.6808 - val_accuracy: 0.6458\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6633 - accuracy: 0.6476 - val_loss: 0.6801 - val_accuracy: 0.6458\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6625 - accuracy: 0.6476 - val_loss: 0.6794 - val_accuracy: 0.6458\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6617 - accuracy: 0.6476 - val_loss: 0.6787 - val_accuracy: 0.6458\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6608 - accuracy: 0.6493 - val_loss: 0.6780 - val_accuracy: 0.6458\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6601 - accuracy: 0.6493 - val_loss: 0.6774 - val_accuracy: 0.6406\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6593 - accuracy: 0.6510 - val_loss: 0.6767 - val_accuracy: 0.6406\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6586 - accuracy: 0.6510 - val_loss: 0.6761 - val_accuracy: 0.6406\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6578 - accuracy: 0.6510 - val_loss: 0.6754 - val_accuracy: 0.6406\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.6571 - accuracy: 0.6510 - val_loss: 0.6748 - val_accuracy: 0.6354\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6563 - accuracy: 0.6510 - val_loss: 0.6742 - val_accuracy: 0.6354\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6556 - accuracy: 0.6510 - val_loss: 0.6736 - val_accuracy: 0.6354\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6549 - accuracy: 0.6545 - val_loss: 0.6730 - val_accuracy: 0.6354\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6542 - accuracy: 0.6562 - val_loss: 0.6724 - val_accuracy: 0.6354\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.6535 - accuracy: 0.6562 - val_loss: 0.6718 - val_accuracy: 0.6354\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6528 - accuracy: 0.6562 - val_loss: 0.6712 - val_accuracy: 0.6354\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6521 - accuracy: 0.6562 - val_loss: 0.6707 - val_accuracy: 0.6354\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6514 - accuracy: 0.6562 - val_loss: 0.6701 - val_accuracy: 0.6354\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6508 - accuracy: 0.6562 - val_loss: 0.6696 - val_accuracy: 0.6354\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6501 - accuracy: 0.6562 - val_loss: 0.6690 - val_accuracy: 0.6354\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6494 - accuracy: 0.6562 - val_loss: 0.6684 - val_accuracy: 0.6354\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6488 - accuracy: 0.6562 - val_loss: 0.6679 - val_accuracy: 0.6406\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6481 - accuracy: 0.6562 - val_loss: 0.6673 - val_accuracy: 0.6406\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6475 - accuracy: 0.6562 - val_loss: 0.6668 - val_accuracy: 0.6406\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6468 - accuracy: 0.6562 - val_loss: 0.6663 - val_accuracy: 0.6406\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.6462 - accuracy: 0.6562 - val_loss: 0.6657 - val_accuracy: 0.6406\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6456 - accuracy: 0.6562 - val_loss: 0.6652 - val_accuracy: 0.6406\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6450 - accuracy: 0.6580 - val_loss: 0.6647 - val_accuracy: 0.6406\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6443 - accuracy: 0.6580 - val_loss: 0.6642 - val_accuracy: 0.6406\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6437 - accuracy: 0.6580 - val_loss: 0.6637 - val_accuracy: 0.6406\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6431 - accuracy: 0.6580 - val_loss: 0.6632 - val_accuracy: 0.6406\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6425 - accuracy: 0.6580 - val_loss: 0.6627 - val_accuracy: 0.6406\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6419 - accuracy: 0.6580 - val_loss: 0.6622 - val_accuracy: 0.6406\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6413 - accuracy: 0.6580 - val_loss: 0.6617 - val_accuracy: 0.6406\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6406 - accuracy: 0.6580 - val_loss: 0.6612 - val_accuracy: 0.6406\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6400 - accuracy: 0.6597 - val_loss: 0.6607 - val_accuracy: 0.6406\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6394 - accuracy: 0.6597 - val_loss: 0.6602 - val_accuracy: 0.6406\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6388 - accuracy: 0.6597 - val_loss: 0.6597 - val_accuracy: 0.6406\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6382 - accuracy: 0.6597 - val_loss: 0.6592 - val_accuracy: 0.6406\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6376 - accuracy: 0.6597 - val_loss: 0.6587 - val_accuracy: 0.6406\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6370 - accuracy: 0.6597 - val_loss: 0.6583 - val_accuracy: 0.6406\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6364 - accuracy: 0.6597 - val_loss: 0.6578 - val_accuracy: 0.6406\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6357 - accuracy: 0.6597 - val_loss: 0.6573 - val_accuracy: 0.6406\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6351 - accuracy: 0.6597 - val_loss: 0.6568 - val_accuracy: 0.6406\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6345 - accuracy: 0.6597 - val_loss: 0.6563 - val_accuracy: 0.6406\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6339 - accuracy: 0.6597 - val_loss: 0.6559 - val_accuracy: 0.6406\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6333 - accuracy: 0.6597 - val_loss: 0.6554 - val_accuracy: 0.6406\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.6327 - accuracy: 0.6597 - val_loss: 0.6549 - val_accuracy: 0.6406\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6321 - accuracy: 0.6597 - val_loss: 0.6544 - val_accuracy: 0.6406\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6315 - accuracy: 0.6597 - val_loss: 0.6539 - val_accuracy: 0.6406\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6309 - accuracy: 0.6597 - val_loss: 0.6535 - val_accuracy: 0.6406\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6302 - accuracy: 0.6597 - val_loss: 0.6530 - val_accuracy: 0.6406\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6296 - accuracy: 0.6597 - val_loss: 0.6525 - val_accuracy: 0.6406\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6290 - accuracy: 0.6597 - val_loss: 0.6520 - val_accuracy: 0.6406\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6283 - accuracy: 0.6597 - val_loss: 0.6515 - val_accuracy: 0.6406\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6277 - accuracy: 0.6597 - val_loss: 0.6510 - val_accuracy: 0.6406\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6271 - accuracy: 0.6597 - val_loss: 0.6505 - val_accuracy: 0.6406\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6264 - accuracy: 0.6615 - val_loss: 0.6500 - val_accuracy: 0.6406\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6258 - accuracy: 0.6615 - val_loss: 0.6495 - val_accuracy: 0.6406\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6251 - accuracy: 0.6615 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6245 - accuracy: 0.6615 - val_loss: 0.6485 - val_accuracy: 0.6406\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.6238 - accuracy: 0.6615 - val_loss: 0.6480 - val_accuracy: 0.6406\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6232 - accuracy: 0.6615 - val_loss: 0.6475 - val_accuracy: 0.6406\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6225 - accuracy: 0.6615 - val_loss: 0.6470 - val_accuracy: 0.6406\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6219 - accuracy: 0.6615 - val_loss: 0.6465 - val_accuracy: 0.6406\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6212 - accuracy: 0.6615 - val_loss: 0.6460 - val_accuracy: 0.6406\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6206 - accuracy: 0.6615 - val_loss: 0.6455 - val_accuracy: 0.6406\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6199 - accuracy: 0.6615 - val_loss: 0.6450 - val_accuracy: 0.6406\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6193 - accuracy: 0.6615 - val_loss: 0.6445 - val_accuracy: 0.6406\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6186 - accuracy: 0.6615 - val_loss: 0.6440 - val_accuracy: 0.6406\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.6179 - accuracy: 0.6615 - val_loss: 0.6434 - val_accuracy: 0.6406\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6172 - accuracy: 0.6615 - val_loss: 0.6429 - val_accuracy: 0.6406\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6165 - accuracy: 0.6615 - val_loss: 0.6424 - val_accuracy: 0.6406\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6158 - accuracy: 0.6615 - val_loss: 0.6418 - val_accuracy: 0.6406\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6152 - accuracy: 0.6615 - val_loss: 0.6413 - val_accuracy: 0.6406\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.6145 - accuracy: 0.6615 - val_loss: 0.6407 - val_accuracy: 0.6406\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6137 - accuracy: 0.6615 - val_loss: 0.6402 - val_accuracy: 0.6406\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6130 - accuracy: 0.6615 - val_loss: 0.6396 - val_accuracy: 0.6406\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6123 - accuracy: 0.6615 - val_loss: 0.6390 - val_accuracy: 0.6406\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6116 - accuracy: 0.6615 - val_loss: 0.6384 - val_accuracy: 0.6406\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6109 - accuracy: 0.6615 - val_loss: 0.6378 - val_accuracy: 0.6458\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6101 - accuracy: 0.6615 - val_loss: 0.6372 - val_accuracy: 0.6458\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6094 - accuracy: 0.6615 - val_loss: 0.6366 - val_accuracy: 0.6458\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.6086 - accuracy: 0.6615 - val_loss: 0.6360 - val_accuracy: 0.6458\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6079 - accuracy: 0.6615 - val_loss: 0.6354 - val_accuracy: 0.6458\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6071 - accuracy: 0.6615 - val_loss: 0.6348 - val_accuracy: 0.6458\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6063 - accuracy: 0.6615 - val_loss: 0.6342 - val_accuracy: 0.6458\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6056 - accuracy: 0.6615 - val_loss: 0.6336 - val_accuracy: 0.6458\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6048 - accuracy: 0.6615 - val_loss: 0.6330 - val_accuracy: 0.6458\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6040 - accuracy: 0.6615 - val_loss: 0.6323 - val_accuracy: 0.6458\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6033 - accuracy: 0.6615 - val_loss: 0.6317 - val_accuracy: 0.6458\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.6025 - accuracy: 0.6615 - val_loss: 0.6311 - val_accuracy: 0.6458\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.6017 - accuracy: 0.6615 - val_loss: 0.6305 - val_accuracy: 0.6458\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.6009 - accuracy: 0.6615 - val_loss: 0.6298 - val_accuracy: 0.6458\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6001 - accuracy: 0.6615 - val_loss: 0.6292 - val_accuracy: 0.6458\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5993 - accuracy: 0.6615 - val_loss: 0.6286 - val_accuracy: 0.6458\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5985 - accuracy: 0.6615 - val_loss: 0.6279 - val_accuracy: 0.6458\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5977 - accuracy: 0.6615 - val_loss: 0.6273 - val_accuracy: 0.6458\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.5969 - accuracy: 0.6615 - val_loss: 0.6266 - val_accuracy: 0.6458\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5960 - accuracy: 0.6615 - val_loss: 0.6260 - val_accuracy: 0.6458\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5952 - accuracy: 0.6615 - val_loss: 0.6253 - val_accuracy: 0.6458\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5943 - accuracy: 0.6615 - val_loss: 0.6246 - val_accuracy: 0.6458\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5934 - accuracy: 0.6597 - val_loss: 0.6239 - val_accuracy: 0.6510\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5926 - accuracy: 0.6597 - val_loss: 0.6233 - val_accuracy: 0.6510\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.5917 - accuracy: 0.6597 - val_loss: 0.6226 - val_accuracy: 0.6510\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5909 - accuracy: 0.6597 - val_loss: 0.6219 - val_accuracy: 0.6510\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5900 - accuracy: 0.6597 - val_loss: 0.6212 - val_accuracy: 0.6510\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.5891 - accuracy: 0.6597 - val_loss: 0.6206 - val_accuracy: 0.6510\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5882 - accuracy: 0.6597 - val_loss: 0.6199 - val_accuracy: 0.6510\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5873 - accuracy: 0.6597 - val_loss: 0.6192 - val_accuracy: 0.6510\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5864 - accuracy: 0.6597 - val_loss: 0.6185 - val_accuracy: 0.6510\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5856 - accuracy: 0.6597 - val_loss: 0.6178 - val_accuracy: 0.6562\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5847 - accuracy: 0.6580 - val_loss: 0.6171 - val_accuracy: 0.6562\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5838 - accuracy: 0.6580 - val_loss: 0.6164 - val_accuracy: 0.6562\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5829 - accuracy: 0.6580 - val_loss: 0.6156 - val_accuracy: 0.6562\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5820 - accuracy: 0.6580 - val_loss: 0.6149 - val_accuracy: 0.6615\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5811 - accuracy: 0.6580 - val_loss: 0.6142 - val_accuracy: 0.6615\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5802 - accuracy: 0.6580 - val_loss: 0.6135 - val_accuracy: 0.6615\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5793 - accuracy: 0.6580 - val_loss: 0.6128 - val_accuracy: 0.6615\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5784 - accuracy: 0.6597 - val_loss: 0.6120 - val_accuracy: 0.6615\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5775 - accuracy: 0.6615 - val_loss: 0.6113 - val_accuracy: 0.6615\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5766 - accuracy: 0.6615 - val_loss: 0.6105 - val_accuracy: 0.6615\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.5758 - accuracy: 0.6615 - val_loss: 0.6098 - val_accuracy: 0.6615\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5748 - accuracy: 0.6615 - val_loss: 0.6090 - val_accuracy: 0.6615\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5739 - accuracy: 0.6615 - val_loss: 0.6083 - val_accuracy: 0.6615\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5730 - accuracy: 0.6615 - val_loss: 0.6075 - val_accuracy: 0.6615\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5721 - accuracy: 0.6615 - val_loss: 0.6067 - val_accuracy: 0.6615\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5712 - accuracy: 0.6615 - val_loss: 0.6060 - val_accuracy: 0.6615\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5702 - accuracy: 0.6615 - val_loss: 0.6052 - val_accuracy: 0.6615\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5693 - accuracy: 0.6615 - val_loss: 0.6044 - val_accuracy: 0.6615\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.5683 - accuracy: 0.6649 - val_loss: 0.6036 - val_accuracy: 0.6615\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5674 - accuracy: 0.6649 - val_loss: 0.6028 - val_accuracy: 0.6615\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5664 - accuracy: 0.6649 - val_loss: 0.6021 - val_accuracy: 0.6615\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5655 - accuracy: 0.6649 - val_loss: 0.6013 - val_accuracy: 0.6615\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5646 - accuracy: 0.6684 - val_loss: 0.6006 - val_accuracy: 0.6615\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5636 - accuracy: 0.6684 - val_loss: 0.5999 - val_accuracy: 0.6615\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.5627 - accuracy: 0.6684 - val_loss: 0.5992 - val_accuracy: 0.6615\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5617 - accuracy: 0.6684 - val_loss: 0.5984 - val_accuracy: 0.6615\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5608 - accuracy: 0.6684 - val_loss: 0.5977 - val_accuracy: 0.6615\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5599 - accuracy: 0.6719 - val_loss: 0.5970 - val_accuracy: 0.6615\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5589 - accuracy: 0.6719 - val_loss: 0.5962 - val_accuracy: 0.6615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5580 - accuracy: 0.6701 - val_loss: 0.5955 - val_accuracy: 0.6615\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5570 - accuracy: 0.6701 - val_loss: 0.5947 - val_accuracy: 0.6615\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5560 - accuracy: 0.6701 - val_loss: 0.5940 - val_accuracy: 0.6615\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5551 - accuracy: 0.6719 - val_loss: 0.5932 - val_accuracy: 0.6615\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5542 - accuracy: 0.6719 - val_loss: 0.5925 - val_accuracy: 0.6615\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5532 - accuracy: 0.6719 - val_loss: 0.5917 - val_accuracy: 0.6615\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5523 - accuracy: 0.6719 - val_loss: 0.5910 - val_accuracy: 0.6615\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5513 - accuracy: 0.6753 - val_loss: 0.5902 - val_accuracy: 0.6615\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5504 - accuracy: 0.6771 - val_loss: 0.5894 - val_accuracy: 0.6667\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5495 - accuracy: 0.6806 - val_loss: 0.5887 - val_accuracy: 0.6667\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5485 - accuracy: 0.6806 - val_loss: 0.5880 - val_accuracy: 0.6667\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5476 - accuracy: 0.6823 - val_loss: 0.5872 - val_accuracy: 0.6667\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5466 - accuracy: 0.6806 - val_loss: 0.5865 - val_accuracy: 0.6719\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.5457 - accuracy: 0.6823 - val_loss: 0.5858 - val_accuracy: 0.6719\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5449 - accuracy: 0.6823 - val_loss: 0.5851 - val_accuracy: 0.6719\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.5440 - accuracy: 0.6806 - val_loss: 0.5844 - val_accuracy: 0.6719\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5431 - accuracy: 0.6806 - val_loss: 0.5837 - val_accuracy: 0.6719\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5422 - accuracy: 0.6823 - val_loss: 0.5830 - val_accuracy: 0.6719\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5414 - accuracy: 0.6823 - val_loss: 0.5824 - val_accuracy: 0.6771\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5405 - accuracy: 0.6840 - val_loss: 0.5817 - val_accuracy: 0.6823\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5396 - accuracy: 0.6858 - val_loss: 0.5810 - val_accuracy: 0.6823\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5388 - accuracy: 0.6840 - val_loss: 0.5803 - val_accuracy: 0.6823\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.5379 - accuracy: 0.6840 - val_loss: 0.5797 - val_accuracy: 0.6823\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5371 - accuracy: 0.6823 - val_loss: 0.5790 - val_accuracy: 0.6823\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5362 - accuracy: 0.6858 - val_loss: 0.5783 - val_accuracy: 0.6875\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5354 - accuracy: 0.6858 - val_loss: 0.5776 - val_accuracy: 0.6875\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5345 - accuracy: 0.6858 - val_loss: 0.5770 - val_accuracy: 0.6875\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5337 - accuracy: 0.6892 - val_loss: 0.5763 - val_accuracy: 0.6875\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5329 - accuracy: 0.6892 - val_loss: 0.5757 - val_accuracy: 0.6875\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5320 - accuracy: 0.6892 - val_loss: 0.5750 - val_accuracy: 0.6875\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5312 - accuracy: 0.6892 - val_loss: 0.5744 - val_accuracy: 0.6823\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5304 - accuracy: 0.6910 - val_loss: 0.5738 - val_accuracy: 0.6823\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5296 - accuracy: 0.6892 - val_loss: 0.5731 - val_accuracy: 0.6823\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5287 - accuracy: 0.6892 - val_loss: 0.5725 - val_accuracy: 0.6823\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.5279 - accuracy: 0.6910 - val_loss: 0.5719 - val_accuracy: 0.6823\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5271 - accuracy: 0.6927 - val_loss: 0.5713 - val_accuracy: 0.6823\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5263 - accuracy: 0.6927 - val_loss: 0.5706 - val_accuracy: 0.6823\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5256 - accuracy: 0.6927 - val_loss: 0.5700 - val_accuracy: 0.6823\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.6927 - val_loss: 0.5694 - val_accuracy: 0.6823\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5240 - accuracy: 0.6927 - val_loss: 0.5688 - val_accuracy: 0.6823\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5233 - accuracy: 0.6944 - val_loss: 0.5683 - val_accuracy: 0.6823\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5225 - accuracy: 0.6927 - val_loss: 0.5677 - val_accuracy: 0.6823\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5217 - accuracy: 0.6979 - val_loss: 0.5671 - val_accuracy: 0.6823\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5210 - accuracy: 0.6997 - val_loss: 0.5666 - val_accuracy: 0.6823\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5202 - accuracy: 0.6997 - val_loss: 0.5660 - val_accuracy: 0.6875\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5194 - accuracy: 0.6997 - val_loss: 0.5655 - val_accuracy: 0.6875\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.5187 - accuracy: 0.6997 - val_loss: 0.5649 - val_accuracy: 0.6927\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5179 - accuracy: 0.6979 - val_loss: 0.5644 - val_accuracy: 0.6927\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5172 - accuracy: 0.6979 - val_loss: 0.5639 - val_accuracy: 0.6979\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5164 - accuracy: 0.6979 - val_loss: 0.5634 - val_accuracy: 0.6927\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.5157 - accuracy: 0.6979 - val_loss: 0.5628 - val_accuracy: 0.6927\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5149 - accuracy: 0.6997 - val_loss: 0.5623 - val_accuracy: 0.6927\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5142 - accuracy: 0.6997 - val_loss: 0.5618 - val_accuracy: 0.6927\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5134 - accuracy: 0.6997 - val_loss: 0.5613 - val_accuracy: 0.6927\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5127 - accuracy: 0.7014 - val_loss: 0.5607 - val_accuracy: 0.6927\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5120 - accuracy: 0.7014 - val_loss: 0.5602 - val_accuracy: 0.6979\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5112 - accuracy: 0.7014 - val_loss: 0.5597 - val_accuracy: 0.6927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5105 - accuracy: 0.7014 - val_loss: 0.5591 - val_accuracy: 0.6927\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5098 - accuracy: 0.6997 - val_loss: 0.5586 - val_accuracy: 0.6927\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5091 - accuracy: 0.7014 - val_loss: 0.5581 - val_accuracy: 0.6927\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5084 - accuracy: 0.7014 - val_loss: 0.5576 - val_accuracy: 0.6979\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5078 - accuracy: 0.6997 - val_loss: 0.5572 - val_accuracy: 0.6979\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5071 - accuracy: 0.7014 - val_loss: 0.5567 - val_accuracy: 0.7031\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5064 - accuracy: 0.7014 - val_loss: 0.5562 - val_accuracy: 0.7083\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5058 - accuracy: 0.7014 - val_loss: 0.5558 - val_accuracy: 0.7083\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5051 - accuracy: 0.7014 - val_loss: 0.5553 - val_accuracy: 0.7083\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5045 - accuracy: 0.7014 - val_loss: 0.5549 - val_accuracy: 0.7083\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5038 - accuracy: 0.7031 - val_loss: 0.5544 - val_accuracy: 0.7135\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5032 - accuracy: 0.7049 - val_loss: 0.5540 - val_accuracy: 0.7135\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.5026 - accuracy: 0.7049 - val_loss: 0.5536 - val_accuracy: 0.7135\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.5019 - accuracy: 0.7049 - val_loss: 0.5532 - val_accuracy: 0.7135\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5014 - accuracy: 0.7049 - val_loss: 0.5528 - val_accuracy: 0.7135\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5008 - accuracy: 0.7066 - val_loss: 0.5524 - val_accuracy: 0.7188\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5002 - accuracy: 0.7066 - val_loss: 0.5520 - val_accuracy: 0.7188\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4996 - accuracy: 0.7066 - val_loss: 0.5516 - val_accuracy: 0.7188\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4991 - accuracy: 0.7101 - val_loss: 0.5512 - val_accuracy: 0.7188\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4985 - accuracy: 0.7101 - val_loss: 0.5509 - val_accuracy: 0.7188\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4980 - accuracy: 0.7101 - val_loss: 0.5505 - val_accuracy: 0.7188\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4975 - accuracy: 0.7101 - val_loss: 0.5502 - val_accuracy: 0.7188\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4969 - accuracy: 0.7118 - val_loss: 0.5498 - val_accuracy: 0.7240\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4964 - accuracy: 0.7118 - val_loss: 0.5495 - val_accuracy: 0.7240\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4959 - accuracy: 0.7118 - val_loss: 0.5491 - val_accuracy: 0.7188\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4954 - accuracy: 0.7101 - val_loss: 0.5488 - val_accuracy: 0.7188\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4949 - accuracy: 0.7101 - val_loss: 0.5484 - val_accuracy: 0.7188\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4944 - accuracy: 0.7101 - val_loss: 0.5481 - val_accuracy: 0.7188\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4939 - accuracy: 0.7118 - val_loss: 0.5478 - val_accuracy: 0.7188\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4934 - accuracy: 0.7135 - val_loss: 0.5474 - val_accuracy: 0.7188\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4929 - accuracy: 0.7135 - val_loss: 0.5471 - val_accuracy: 0.7188\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.7135 - val_loss: 0.5468 - val_accuracy: 0.7135\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4920 - accuracy: 0.7135 - val_loss: 0.5465 - val_accuracy: 0.7135\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4915 - accuracy: 0.7153 - val_loss: 0.5462 - val_accuracy: 0.7083\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4911 - accuracy: 0.7170 - val_loss: 0.5459 - val_accuracy: 0.7135\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4906 - accuracy: 0.7205 - val_loss: 0.5456 - val_accuracy: 0.7135\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4902 - accuracy: 0.7170 - val_loss: 0.5453 - val_accuracy: 0.7135\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4898 - accuracy: 0.7170 - val_loss: 0.5450 - val_accuracy: 0.7083\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4893 - accuracy: 0.7188 - val_loss: 0.5448 - val_accuracy: 0.7135\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4889 - accuracy: 0.7170 - val_loss: 0.5445 - val_accuracy: 0.7135\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4885 - accuracy: 0.7170 - val_loss: 0.5442 - val_accuracy: 0.7135\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4881 - accuracy: 0.7188 - val_loss: 0.5439 - val_accuracy: 0.7135\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4877 - accuracy: 0.7205 - val_loss: 0.5436 - val_accuracy: 0.7135\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4873 - accuracy: 0.7205 - val_loss: 0.5434 - val_accuracy: 0.7135\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4869 - accuracy: 0.7205 - val_loss: 0.5431 - val_accuracy: 0.7135\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4865 - accuracy: 0.7222 - val_loss: 0.5428 - val_accuracy: 0.7135\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4861 - accuracy: 0.7222 - val_loss: 0.5425 - val_accuracy: 0.7135\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4857 - accuracy: 0.7240 - val_loss: 0.5422 - val_accuracy: 0.7135\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4853 - accuracy: 0.7240 - val_loss: 0.5420 - val_accuracy: 0.7135\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4849 - accuracy: 0.7257 - val_loss: 0.5417 - val_accuracy: 0.7135\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.7257 - val_loss: 0.5414 - val_accuracy: 0.7188\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4841 - accuracy: 0.7274 - val_loss: 0.5411 - val_accuracy: 0.7188\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4837 - accuracy: 0.7257 - val_loss: 0.5408 - val_accuracy: 0.7240\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4833 - accuracy: 0.7292 - val_loss: 0.5406 - val_accuracy: 0.7240\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4829 - accuracy: 0.7292 - val_loss: 0.5403 - val_accuracy: 0.7240\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4826 - accuracy: 0.7309 - val_loss: 0.5401 - val_accuracy: 0.7240\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4822 - accuracy: 0.7309 - val_loss: 0.5398 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4819 - accuracy: 0.7309 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4815 - accuracy: 0.7309 - val_loss: 0.5393 - val_accuracy: 0.7292\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4811 - accuracy: 0.7292 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4808 - accuracy: 0.7292 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4804 - accuracy: 0.7292 - val_loss: 0.5386 - val_accuracy: 0.7396\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4801 - accuracy: 0.7361 - val_loss: 0.5383 - val_accuracy: 0.7292\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4798 - accuracy: 0.7378 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4795 - accuracy: 0.7396 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4791 - accuracy: 0.7413 - val_loss: 0.5377 - val_accuracy: 0.7240\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4788 - accuracy: 0.7431 - val_loss: 0.5374 - val_accuracy: 0.7240\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4785 - accuracy: 0.7448 - val_loss: 0.5372 - val_accuracy: 0.7240\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4782 - accuracy: 0.7465 - val_loss: 0.5371 - val_accuracy: 0.7240\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4779 - accuracy: 0.7500 - val_loss: 0.5369 - val_accuracy: 0.7240\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4776 - accuracy: 0.7483 - val_loss: 0.5367 - val_accuracy: 0.7240\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4773 - accuracy: 0.7500 - val_loss: 0.5365 - val_accuracy: 0.7292\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4770 - accuracy: 0.7465 - val_loss: 0.5363 - val_accuracy: 0.7344\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4767 - accuracy: 0.7500 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4764 - accuracy: 0.7500 - val_loss: 0.5359 - val_accuracy: 0.7448\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4762 - accuracy: 0.7517 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4759 - accuracy: 0.7535 - val_loss: 0.5356 - val_accuracy: 0.7448\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.7535 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4753 - accuracy: 0.7535 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4750 - accuracy: 0.7552 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4748 - accuracy: 0.7552 - val_loss: 0.5349 - val_accuracy: 0.7500\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.7569 - val_loss: 0.5348 - val_accuracy: 0.7500\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4743 - accuracy: 0.7604 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4740 - accuracy: 0.7604 - val_loss: 0.5346 - val_accuracy: 0.7552\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4738 - accuracy: 0.7604 - val_loss: 0.5345 - val_accuracy: 0.7552\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4736 - accuracy: 0.7622 - val_loss: 0.5344 - val_accuracy: 0.7552\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.7569 - val_loss: 0.5343 - val_accuracy: 0.7552\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4731 - accuracy: 0.7569 - val_loss: 0.5342 - val_accuracy: 0.7552\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4729 - accuracy: 0.7569 - val_loss: 0.5341 - val_accuracy: 0.7552\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4727 - accuracy: 0.7552 - val_loss: 0.5340 - val_accuracy: 0.7604\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4725 - accuracy: 0.7587 - val_loss: 0.5339 - val_accuracy: 0.7604\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4723 - accuracy: 0.7569 - val_loss: 0.5338 - val_accuracy: 0.7604\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4721 - accuracy: 0.7569 - val_loss: 0.5337 - val_accuracy: 0.7604\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4719 - accuracy: 0.7569 - val_loss: 0.5337 - val_accuracy: 0.7604\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4717 - accuracy: 0.7569 - val_loss: 0.5336 - val_accuracy: 0.7604\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.7587 - val_loss: 0.5335 - val_accuracy: 0.7552\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4713 - accuracy: 0.7587 - val_loss: 0.5334 - val_accuracy: 0.7552\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.7587 - val_loss: 0.5333 - val_accuracy: 0.7552\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.7587 - val_loss: 0.5332 - val_accuracy: 0.7552\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4707 - accuracy: 0.7604 - val_loss: 0.5332 - val_accuracy: 0.7552\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.7604 - val_loss: 0.5331 - val_accuracy: 0.7552\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4704 - accuracy: 0.7622 - val_loss: 0.5330 - val_accuracy: 0.7552\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4701 - accuracy: 0.7622 - val_loss: 0.5329 - val_accuracy: 0.7552\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4699 - accuracy: 0.7622 - val_loss: 0.5328 - val_accuracy: 0.7552\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4698 - accuracy: 0.7622 - val_loss: 0.5327 - val_accuracy: 0.7552\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4696 - accuracy: 0.7604 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.4694 - accuracy: 0.7604 - val_loss: 0.5325 - val_accuracy: 0.7552\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4692 - accuracy: 0.7622 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4690 - accuracy: 0.7622 - val_loss: 0.5324 - val_accuracy: 0.7552\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4688 - accuracy: 0.7604 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4685 - accuracy: 0.7604 - val_loss: 0.5322 - val_accuracy: 0.7552\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4684 - accuracy: 0.7604 - val_loss: 0.5321 - val_accuracy: 0.7552\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4681 - accuracy: 0.7604 - val_loss: 0.5320 - val_accuracy: 0.7552\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.7622 - val_loss: 0.5319 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4677 - accuracy: 0.7622 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4675 - accuracy: 0.7622 - val_loss: 0.5318 - val_accuracy: 0.7552\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4673 - accuracy: 0.7622 - val_loss: 0.5317 - val_accuracy: 0.7552\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4671 - accuracy: 0.7639 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4669 - accuracy: 0.7639 - val_loss: 0.5316 - val_accuracy: 0.7552\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4668 - accuracy: 0.7639 - val_loss: 0.5315 - val_accuracy: 0.7552\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4666 - accuracy: 0.7639 - val_loss: 0.5314 - val_accuracy: 0.7552\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4664 - accuracy: 0.7622 - val_loss: 0.5314 - val_accuracy: 0.7552\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4663 - accuracy: 0.7604 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4661 - accuracy: 0.7639 - val_loss: 0.5313 - val_accuracy: 0.7552\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4659 - accuracy: 0.7622 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4658 - accuracy: 0.7639 - val_loss: 0.5312 - val_accuracy: 0.7552\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4656 - accuracy: 0.7656 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4655 - accuracy: 0.7674 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4653 - accuracy: 0.7691 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4652 - accuracy: 0.7674 - val_loss: 0.5310 - val_accuracy: 0.7552\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4650 - accuracy: 0.7708 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4649 - accuracy: 0.7674 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4647 - accuracy: 0.7674 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4645 - accuracy: 0.7674 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4644 - accuracy: 0.7674 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4643 - accuracy: 0.7691 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4641 - accuracy: 0.7674 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4640 - accuracy: 0.7708 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4637 - accuracy: 0.7726 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.5306 - val_accuracy: 0.7344\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4632 - accuracy: 0.7726 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4630 - accuracy: 0.7708 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4628 - accuracy: 0.7708 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4627 - accuracy: 0.7708 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4625 - accuracy: 0.7743 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4624 - accuracy: 0.7743 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4623 - accuracy: 0.7743 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4622 - accuracy: 0.7743 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.5304 - val_accuracy: 0.7344\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4608 - accuracy: 0.7795 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4605 - accuracy: 0.7812 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4602 - accuracy: 0.7812 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4601 - accuracy: 0.7812 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.5303 - val_accuracy: 0.7344\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.5303 - val_accuracy: 0.7292\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4597 - accuracy: 0.7812 - val_loss: 0.5303 - val_accuracy: 0.7292\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.5303 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.5303 - val_accuracy: 0.7292\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.5303 - val_accuracy: 0.7292\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.5303 - val_accuracy: 0.7292\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.5304 - val_accuracy: 0.7292\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.5304 - val_accuracy: 0.7292\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.5304 - val_accuracy: 0.7292\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.5304 - val_accuracy: 0.7292\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7344\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4580 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4576 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4575 - accuracy: 0.7830 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4572 - accuracy: 0.7830 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4571 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4570 - accuracy: 0.7830 - val_loss: 0.5309 - val_accuracy: 0.7396\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4569 - accuracy: 0.7830 - val_loss: 0.5310 - val_accuracy: 0.7396\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4568 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7396\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4567 - accuracy: 0.7847 - val_loss: 0.5310 - val_accuracy: 0.7344\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4566 - accuracy: 0.7847 - val_loss: 0.5311 - val_accuracy: 0.7344\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4565 - accuracy: 0.7865 - val_loss: 0.5311 - val_accuracy: 0.7344\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4564 - accuracy: 0.7865 - val_loss: 0.5311 - val_accuracy: 0.7344\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4563 - accuracy: 0.7865 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4562 - accuracy: 0.7865 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4561 - accuracy: 0.7847 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.7847 - val_loss: 0.5313 - val_accuracy: 0.7344\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4559 - accuracy: 0.7847 - val_loss: 0.5313 - val_accuracy: 0.7344\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4558 - accuracy: 0.7847 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4557 - accuracy: 0.7847 - val_loss: 0.5314 - val_accuracy: 0.7344\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4556 - accuracy: 0.7847 - val_loss: 0.5314 - val_accuracy: 0.7292\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4554 - accuracy: 0.7847 - val_loss: 0.5315 - val_accuracy: 0.7292\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4553 - accuracy: 0.7847 - val_loss: 0.5315 - val_accuracy: 0.7292\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4552 - accuracy: 0.7847 - val_loss: 0.5315 - val_accuracy: 0.7292\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4551 - accuracy: 0.7865 - val_loss: 0.5316 - val_accuracy: 0.7292\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4550 - accuracy: 0.7865 - val_loss: 0.5316 - val_accuracy: 0.7292\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4549 - accuracy: 0.7865 - val_loss: 0.5317 - val_accuracy: 0.7292\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.5317 - val_accuracy: 0.7292\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.5317 - val_accuracy: 0.7292\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.5318 - val_accuracy: 0.7292\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4544 - accuracy: 0.7882 - val_loss: 0.5318 - val_accuracy: 0.7292\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.7882 - val_loss: 0.5319 - val_accuracy: 0.7292\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4541 - accuracy: 0.7882 - val_loss: 0.5319 - val_accuracy: 0.7292\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4540 - accuracy: 0.7882 - val_loss: 0.5320 - val_accuracy: 0.7292\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4539 - accuracy: 0.7882 - val_loss: 0.5321 - val_accuracy: 0.7292\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4538 - accuracy: 0.7882 - val_loss: 0.5321 - val_accuracy: 0.7292\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4537 - accuracy: 0.7882 - val_loss: 0.5322 - val_accuracy: 0.7344\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4536 - accuracy: 0.7882 - val_loss: 0.5322 - val_accuracy: 0.7344\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4534 - accuracy: 0.7882 - val_loss: 0.5323 - val_accuracy: 0.7292\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4533 - accuracy: 0.7882 - val_loss: 0.5324 - val_accuracy: 0.7292\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4532 - accuracy: 0.7882 - val_loss: 0.5324 - val_accuracy: 0.7344\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.5325 - val_accuracy: 0.7344\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4530 - accuracy: 0.7882 - val_loss: 0.5325 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4528 - accuracy: 0.7882 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4527 - accuracy: 0.7882 - val_loss: 0.5327 - val_accuracy: 0.7344\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4526 - accuracy: 0.7882 - val_loss: 0.5327 - val_accuracy: 0.7344\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4525 - accuracy: 0.7865 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4523 - accuracy: 0.7882 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4522 - accuracy: 0.7865 - val_loss: 0.5329 - val_accuracy: 0.7396\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4520 - accuracy: 0.7865 - val_loss: 0.5329 - val_accuracy: 0.7448\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.7865 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4518 - accuracy: 0.7865 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4517 - accuracy: 0.7865 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4516 - accuracy: 0.7865 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4514 - accuracy: 0.7865 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4514 - accuracy: 0.7865 - val_loss: 0.5331 - val_accuracy: 0.7448\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4513 - accuracy: 0.7882 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4512 - accuracy: 0.7882 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4511 - accuracy: 0.7899 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4510 - accuracy: 0.7899 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4509 - accuracy: 0.7899 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4508 - accuracy: 0.7899 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4505 - accuracy: 0.7899 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4505 - accuracy: 0.7882 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4503 - accuracy: 0.7917 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4502 - accuracy: 0.7917 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4501 - accuracy: 0.7917 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4501 - accuracy: 0.7917 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4500 - accuracy: 0.7917 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4499 - accuracy: 0.7899 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4498 - accuracy: 0.7917 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4498 - accuracy: 0.7917 - val_loss: 0.5335 - val_accuracy: 0.7396\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.7917 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4496 - accuracy: 0.7917 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4495 - accuracy: 0.7917 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4494 - accuracy: 0.7917 - val_loss: 0.5336 - val_accuracy: 0.7396\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4494 - accuracy: 0.7917 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4493 - accuracy: 0.7934 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4492 - accuracy: 0.7934 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4491 - accuracy: 0.7934 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4491 - accuracy: 0.7934 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4490 - accuracy: 0.7934 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4489 - accuracy: 0.7951 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4488 - accuracy: 0.7951 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4488 - accuracy: 0.7951 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4487 - accuracy: 0.7951 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4486 - accuracy: 0.7951 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4486 - accuracy: 0.7951 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.7969 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4484 - accuracy: 0.7969 - val_loss: 0.5340 - val_accuracy: 0.7396\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4484 - accuracy: 0.7934 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4483 - accuracy: 0.7951 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4482 - accuracy: 0.7951 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4482 - accuracy: 0.7951 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4481 - accuracy: 0.7951 - val_loss: 0.5342 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4480 - accuracy: 0.7934 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4480 - accuracy: 0.7934 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.7934 - val_loss: 0.5342 - val_accuracy: 0.7396\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.7934 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.7934 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4477 - accuracy: 0.7934 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4477 - accuracy: 0.7934 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4476 - accuracy: 0.7934 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4475 - accuracy: 0.7934 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.7934 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4474 - accuracy: 0.7934 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4473 - accuracy: 0.7934 - val_loss: 0.5343 - val_accuracy: 0.7344\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4473 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4472 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4472 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4469 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4468 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4468 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4467 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4466 - accuracy: 0.7934 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4464 - accuracy: 0.7917 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.7917 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4463 - accuracy: 0.7934 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4463 - accuracy: 0.7934 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4462 - accuracy: 0.7934 - val_loss: 0.5345 - val_accuracy: 0.7344\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4461 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7344\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4461 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7344\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7344\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7344\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7344\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7344\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4459 - accuracy: 0.7934 - val_loss: 0.5346 - val_accuracy: 0.7344\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4458 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7344\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7344\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7344\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4456 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4455 - accuracy: 0.7951 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4455 - accuracy: 0.7951 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7951 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.7951 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4453 - accuracy: 0.7951 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.7934 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7934 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.7934 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7240\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7240\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4449 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7240\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7240\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7240\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.7934 - val_loss: 0.5349 - val_accuracy: 0.7240\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7951 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4444 - accuracy: 0.7951 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7240\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7240\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7240\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7240\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.5351 - val_accuracy: 0.7240\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.5352 - val_accuracy: 0.7240\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.5352 - val_accuracy: 0.7240\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.5352 - val_accuracy: 0.7240\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4439 - accuracy: 0.7969 - val_loss: 0.5352 - val_accuracy: 0.7240\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.7969 - val_loss: 0.5352 - val_accuracy: 0.7240\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7240\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4438 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7240\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4438 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7240\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4437 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7240\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4437 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7240\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4436 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7240\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4436 - accuracy: 0.7969 - val_loss: 0.5353 - val_accuracy: 0.7240\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4435 - accuracy: 0.7969 - val_loss: 0.5354 - val_accuracy: 0.7240\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.7969 - val_loss: 0.5354 - val_accuracy: 0.7240\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4435 - accuracy: 0.7969 - val_loss: 0.5354 - val_accuracy: 0.7240\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4434 - accuracy: 0.7969 - val_loss: 0.5354 - val_accuracy: 0.7240\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.7969 - val_loss: 0.5354 - val_accuracy: 0.7240\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.7986 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.7986 - val_loss: 0.5354 - val_accuracy: 0.7292\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.7986 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7969 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.7986 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.7986 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4431 - accuracy: 0.7986 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.7986 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4430 - accuracy: 0.7986 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4430 - accuracy: 0.7986 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.7986 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.7986 - val_loss: 0.5356 - val_accuracy: 0.7292\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.7986 - val_loss: 0.5357 - val_accuracy: 0.7240\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.7986 - val_loss: 0.5357 - val_accuracy: 0.7240\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4428 - accuracy: 0.7986 - val_loss: 0.5357 - val_accuracy: 0.7240\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.7986 - val_loss: 0.5357 - val_accuracy: 0.7188\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.7986 - val_loss: 0.5358 - val_accuracy: 0.7188\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4426 - accuracy: 0.7969 - val_loss: 0.5358 - val_accuracy: 0.7188\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4426 - accuracy: 0.7969 - val_loss: 0.5358 - val_accuracy: 0.7188\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4425 - accuracy: 0.7969 - val_loss: 0.5358 - val_accuracy: 0.7188\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.7969 - val_loss: 0.5359 - val_accuracy: 0.7188\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4425 - accuracy: 0.7969 - val_loss: 0.5359 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7969 - val_loss: 0.5359 - val_accuracy: 0.7188\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.7969 - val_loss: 0.5359 - val_accuracy: 0.7188\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4423 - accuracy: 0.7969 - val_loss: 0.5360 - val_accuracy: 0.7188\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.7969 - val_loss: 0.5360 - val_accuracy: 0.7188\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4422 - accuracy: 0.7969 - val_loss: 0.5360 - val_accuracy: 0.7188\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4422 - accuracy: 0.7969 - val_loss: 0.5360 - val_accuracy: 0.7188\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4421 - accuracy: 0.7969 - val_loss: 0.5361 - val_accuracy: 0.7188\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7969 - val_loss: 0.5361 - val_accuracy: 0.7188\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7969 - val_loss: 0.5361 - val_accuracy: 0.7188\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.7969 - val_loss: 0.5361 - val_accuracy: 0.7188\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5362 - val_accuracy: 0.7188\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5362 - val_accuracy: 0.7188\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5362 - val_accuracy: 0.7188\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4418 - accuracy: 0.7969 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.7969 - val_loss: 0.5363 - val_accuracy: 0.7188\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.7969 - val_loss: 0.5364 - val_accuracy: 0.7188\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5364 - val_accuracy: 0.7188\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5364 - val_accuracy: 0.7188\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4416 - accuracy: 0.7969 - val_loss: 0.5365 - val_accuracy: 0.7188\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4415 - accuracy: 0.7969 - val_loss: 0.5365 - val_accuracy: 0.7188\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.7969 - val_loss: 0.5365 - val_accuracy: 0.7188\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.7969 - val_loss: 0.5366 - val_accuracy: 0.7188\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4414 - accuracy: 0.7969 - val_loss: 0.5366 - val_accuracy: 0.7188\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5366 - val_accuracy: 0.7188\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5366 - val_accuracy: 0.7188\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.7969 - val_loss: 0.5367 - val_accuracy: 0.7188\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7969 - val_loss: 0.5367 - val_accuracy: 0.7188\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.7969 - val_loss: 0.5367 - val_accuracy: 0.7188\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7969 - val_loss: 0.5368 - val_accuracy: 0.7188\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7969 - val_loss: 0.5368 - val_accuracy: 0.7188\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4410 - accuracy: 0.7969 - val_loss: 0.5368 - val_accuracy: 0.7188\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7969 - val_loss: 0.5368 - val_accuracy: 0.7188\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7969 - val_loss: 0.5369 - val_accuracy: 0.7188\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7969 - val_loss: 0.5369 - val_accuracy: 0.7188\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4409 - accuracy: 0.7969 - val_loss: 0.5369 - val_accuracy: 0.7188\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4409 - accuracy: 0.7969 - val_loss: 0.5369 - val_accuracy: 0.7188\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.7969 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.7969 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7969 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.7969 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.7969 - val_loss: 0.5371 - val_accuracy: 0.7188\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.7969 - val_loss: 0.5371 - val_accuracy: 0.7188\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.7969 - val_loss: 0.5371 - val_accuracy: 0.7188\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.7969 - val_loss: 0.5371 - val_accuracy: 0.7188\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4405 - accuracy: 0.7969 - val_loss: 0.5372 - val_accuracy: 0.7188\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4404 - accuracy: 0.7969 - val_loss: 0.5372 - val_accuracy: 0.7188\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7969 - val_loss: 0.5372 - val_accuracy: 0.7188\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7969 - val_loss: 0.5372 - val_accuracy: 0.7188\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.7969 - val_loss: 0.5372 - val_accuracy: 0.7188\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4403 - accuracy: 0.7969 - val_loss: 0.5373 - val_accuracy: 0.7188\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.7969 - val_loss: 0.5373 - val_accuracy: 0.7188\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4403 - accuracy: 0.7969 - val_loss: 0.5373 - val_accuracy: 0.7188\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.5373 - val_accuracy: 0.7188\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.5373 - val_accuracy: 0.7188\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5374 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7969 - val_loss: 0.5374 - val_accuracy: 0.7188\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4399 - accuracy: 0.7969 - val_loss: 0.5375 - val_accuracy: 0.7188\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4398 - accuracy: 0.7969 - val_loss: 0.5375 - val_accuracy: 0.7188\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4398 - accuracy: 0.7969 - val_loss: 0.5375 - val_accuracy: 0.7188\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4397 - accuracy: 0.7969 - val_loss: 0.5375 - val_accuracy: 0.7188\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.7969 - val_loss: 0.5375 - val_accuracy: 0.7188\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5375 - val_accuracy: 0.7188\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5376 - val_accuracy: 0.7188\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4396 - accuracy: 0.7969 - val_loss: 0.5376 - val_accuracy: 0.7188\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7969 - val_loss: 0.5376 - val_accuracy: 0.7188\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.7969 - val_loss: 0.5376 - val_accuracy: 0.7188\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4394 - accuracy: 0.7969 - val_loss: 0.5376 - val_accuracy: 0.7188\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4394 - accuracy: 0.7969 - val_loss: 0.5376 - val_accuracy: 0.7188\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4393 - accuracy: 0.7969 - val_loss: 0.5376 - val_accuracy: 0.7188\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4393 - accuracy: 0.7969 - val_loss: 0.5377 - val_accuracy: 0.7188\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.7969 - val_loss: 0.5377 - val_accuracy: 0.7188\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.7969 - val_loss: 0.5377 - val_accuracy: 0.7188\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4392 - accuracy: 0.7969 - val_loss: 0.5377 - val_accuracy: 0.7188\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4391 - accuracy: 0.7969 - val_loss: 0.5377 - val_accuracy: 0.7188\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.7969 - val_loss: 0.5377 - val_accuracy: 0.7188\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.7969 - val_loss: 0.5377 - val_accuracy: 0.7188\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5377 - val_accuracy: 0.7188\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5378 - val_accuracy: 0.7188\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5378 - val_accuracy: 0.7188\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4389 - accuracy: 0.7969 - val_loss: 0.5378 - val_accuracy: 0.7188\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.7969 - val_loss: 0.5378 - val_accuracy: 0.7188\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.7969 - val_loss: 0.5378 - val_accuracy: 0.7188\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.7986 - val_loss: 0.5379 - val_accuracy: 0.7188\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.7986 - val_loss: 0.5379 - val_accuracy: 0.7188\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7986 - val_loss: 0.5379 - val_accuracy: 0.7188\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.7986 - val_loss: 0.5379 - val_accuracy: 0.7188\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.7986 - val_loss: 0.5379 - val_accuracy: 0.7188\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4385 - accuracy: 0.7986 - val_loss: 0.5379 - val_accuracy: 0.7188\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7986 - val_loss: 0.5379 - val_accuracy: 0.7188\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4385 - accuracy: 0.7986 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.7986 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4384 - accuracy: 0.7986 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.7986 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4383 - accuracy: 0.7986 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4383 - accuracy: 0.7986 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4383 - accuracy: 0.7986 - val_loss: 0.5380 - val_accuracy: 0.7188\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.7986 - val_loss: 0.5381 - val_accuracy: 0.7135\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.7986 - val_loss: 0.5381 - val_accuracy: 0.7135\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.8003 - val_loss: 0.5381 - val_accuracy: 0.7135\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7986 - val_loss: 0.5381 - val_accuracy: 0.7135\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.7986 - val_loss: 0.5381 - val_accuracy: 0.7135\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.8003 - val_loss: 0.5381 - val_accuracy: 0.7135\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4380 - accuracy: 0.8003 - val_loss: 0.5381 - val_accuracy: 0.7135\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.8003 - val_loss: 0.5381 - val_accuracy: 0.7135\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.7986 - val_loss: 0.5381 - val_accuracy: 0.7135\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.8003 - val_loss: 0.5381 - val_accuracy: 0.7135\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.7986 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.7986 - val_loss: 0.5381 - val_accuracy: 0.7188\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.7986 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.7986 - val_loss: 0.5382 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4378 - accuracy: 0.8003 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.8003 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.8003 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.8003 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.8003 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7240\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4374 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7188\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.8021 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4373 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4366 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4366 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4364 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4365 - accuracy: 0.8021 - val_loss: 0.5383 - val_accuracy: 0.7240\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4364 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4363 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4362 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.8021 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.5384 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4360 - accuracy: 0.8021 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4360 - accuracy: 0.8021 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4359 - accuracy: 0.8021 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4359 - accuracy: 0.8021 - val_loss: 0.5385 - val_accuracy: 0.7240\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4359 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4358 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.5386 - val_accuracy: 0.7240\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4356 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4356 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4356 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4356 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4355 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4355 - accuracy: 0.8021 - val_loss: 0.5386 - val_accuracy: 0.7292\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4355 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4355 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4355 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4354 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4354 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4353 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4354 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4353 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4353 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4353 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4353 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4352 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4352 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.8021 - val_loss: 0.5387 - val_accuracy: 0.7292\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4351 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4351 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4350 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.8038 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4349 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4349 - accuracy: 0.8021 - val_loss: 0.5388 - val_accuracy: 0.7292\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4349 - accuracy: 0.8021 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4348 - accuracy: 0.8021 - val_loss: 0.5389 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4348 - accuracy: 0.8021 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4348 - accuracy: 0.8021 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.8021 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4347 - accuracy: 0.8021 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4348 - accuracy: 0.8021 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4347 - accuracy: 0.8021 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4347 - accuracy: 0.8038 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4347 - accuracy: 0.8038 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4347 - accuracy: 0.8038 - val_loss: 0.5389 - val_accuracy: 0.7292\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4346 - accuracy: 0.8038 - val_loss: 0.5389 - val_accuracy: 0.7344\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4347 - accuracy: 0.8038 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4346 - accuracy: 0.8073 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4346 - accuracy: 0.8056 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4346 - accuracy: 0.8056 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4346 - accuracy: 0.8056 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4345 - accuracy: 0.8038 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4345 - accuracy: 0.8056 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4345 - accuracy: 0.8021 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4345 - accuracy: 0.8073 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4344 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.8073 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4344 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.8021 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4343 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4343 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4343 - accuracy: 0.8038 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.8038 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4342 - accuracy: 0.8056 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.8038 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.8038 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.8038 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.8038 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.8038 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4341 - accuracy: 0.8056 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4341 - accuracy: 0.8038 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.8038 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.8038 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4340 - accuracy: 0.8056 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4340 - accuracy: 0.8038 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.8038 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4340 - accuracy: 0.8038 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4340 - accuracy: 0.8038 - val_loss: 0.5392 - val_accuracy: 0.7396\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4339 - accuracy: 0.8056 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4339 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4339 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4339 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4338 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4338 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4337 - accuracy: 0.8021 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.8021 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4337 - accuracy: 0.8056 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4336 - accuracy: 0.8056 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4336 - accuracy: 0.8038 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4336 - accuracy: 0.8021 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.8038 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4336 - accuracy: 0.8021 - val_loss: 0.5393 - val_accuracy: 0.7396\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4335 - accuracy: 0.8038 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4335 - accuracy: 0.8038 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4335 - accuracy: 0.8021 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4335 - accuracy: 0.8038 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4334 - accuracy: 0.8038 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4335 - accuracy: 0.8021 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4334 - accuracy: 0.8021 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4334 - accuracy: 0.8038 - val_loss: 0.5394 - val_accuracy: 0.7396\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4334 - accuracy: 0.8021 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.8038 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4334 - accuracy: 0.8038 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.8021 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4333 - accuracy: 0.8021 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.8038 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4333 - accuracy: 0.8021 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.8003 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.8003 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.8021 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4332 - accuracy: 0.8021 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.8003 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.8038 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4332 - accuracy: 0.8003 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.8003 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5395 - val_accuracy: 0.7344\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.8003 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.8003 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.7986 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4330 - accuracy: 0.7986 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4330 - accuracy: 0.8038 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.8003 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4329 - accuracy: 0.8003 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4329 - accuracy: 0.8021 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4329 - accuracy: 0.7986 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4328 - accuracy: 0.8003 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.8003 - val_loss: 0.5397 - val_accuracy: 0.7344\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5398 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4327 - accuracy: 0.7969 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.8003 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4326 - accuracy: 0.8038 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4326 - accuracy: 0.7986 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.5399 - val_accuracy: 0.7344\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.5401 - val_accuracy: 0.7344\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.8003 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1026/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 18ms/step - loss: 0.4319 - accuracy: 0.8003 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4316 - accuracy: 0.8003 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4316 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4314 - accuracy: 0.8003 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4314 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4311 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1082/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4310 - accuracy: 0.8021 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.4309 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4309 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4307 - accuracy: 0.8003 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4306 - accuracy: 0.7986 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4305 - accuracy: 0.8003 - val_loss: 0.5406 - val_accuracy: 0.7396\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4305 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4303 - accuracy: 0.8003 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1138/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.8003 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4295 - accuracy: 0.7951 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7448\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.7951 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.7951 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.7951 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4293 - accuracy: 0.7951 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1194/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4292 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4292 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4291 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4291 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7448\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4289 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4285 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1250/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4283 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.7951 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.7951 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7951 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.7951 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4277 - accuracy: 0.7951 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.7951 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1306/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.7951 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4273 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4272 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7292\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4270 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1362/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7344\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4266 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4262 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4261 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4261 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1418/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4260 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4258 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4258 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4258 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4258 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4258 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4256 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4256 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4256 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4256 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4255 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4254 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4254 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4253 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1474/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4252 - accuracy: 0.7986 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7396\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4249 - accuracy: 0.7969 - val_loss: 0.5406 - val_accuracy: 0.7448\n"
     ]
    }
   ],
   "source": [
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 6 hidden nodes, relu activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss over iterations: Pela curva de validation loss, a partir da iteração 400 houve uma piora na maneira em que o modelo se ajusta a novos dados, e o ajuste a dados de treino seque caindo, o ideal.\n",
    "\n",
    "### Accuracy over iterations: A accurácia da validação de novos dados cai em torno da iteração número 300, enquanto para dados de treino segue a melhorar. \n",
    "\n",
    "### Este modelo para dados de validação piora muito a partir da iteração 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "\n",
      "accuracy is 0.641\n",
      "roc-auc is 0.792\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "predict_x = model_1.predict(X_test) \n",
    "y_pred_class_nn_2 = np.argmax(predict_x,axis=1)\n",
    "\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A acurácia, previsão de pessoas que têm diabetes no modelo ficou em torno de 64%. A rurva ROC-AUC para avaliar a performance do modelo nos diz que nosso modelo consegue distinguir entre pacientes com e sem diabetes a uma taxa de aproximadamente 79%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
